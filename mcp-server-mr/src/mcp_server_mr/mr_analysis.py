# src/mcp_server_mr/mr_analysis.py
"""
Mendelian Randomization analysis implementation.
This module provides Python-based implementations of common MR methods.
"""

import numpy as np
import pandas as pd
from scipy import stats
from typing import List, Tuple, Dict, Any
import logging

from .models import HarmonizedDataPoint, MRMethodResult, SensitivityAnalysis

logger = logging.getLogger(__name__)

class MRAnalyzer:
    """
    Main class for performing Mendelian Randomization analysis.
    """
    
    def __init__(self, data: List[HarmonizedDataPoint]):
        """
        Initialize the MR analyzer with harmonized data.

        Args:
            data: List of harmonized SNP data points from eQTL and GWAS APIs
        """
        if data is None or (hasattr(data, 'empty') and data.empty) or (hasattr(data, '__len__') and len(data) == 0):
            raise ValueError("âŒ æœªæä¾›harmonizedæ•°æ®ï¼ŒMRåˆ†æéœ€è¦çœŸå®çš„SNPæ•°æ®")

        # éªŒè¯æ•°æ®æ¥æºçš„çœŸå®æ€§
        self._validate_data_authenticity(data)

        self.data = data
        self.df = self._prepare_dataframe()

        logger.info(f"âœ… MRåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨ {len(data)} ä¸ªçœŸå®SNPæ•°æ®ç‚¹")

    def _validate_data_authenticity(self, data: List[HarmonizedDataPoint]):
        """
        éªŒè¯è¾“å…¥æ•°æ®çš„çœŸå®æ€§ï¼Œä¸¥ç¦ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        """
        logger.info("ğŸ” éªŒè¯MRè¾“å…¥æ•°æ®çš„çœŸå®æ€§...")

        for i, snp_data in enumerate(data):
            # æ£€æŸ¥SNP IDæ ¼å¼
            if not snp_data.SNP or len(snp_data.SNP) < 3:
                raise ValueError(f"âŒ SNP {i+1} IDæ— æ•ˆ: {snp_data.SNP}")

            # æ£€æŸ¥æ•ˆåº”å€¼çš„åˆç†æ€§
            if abs(snp_data.beta_exposure) > 10 or abs(snp_data.beta_outcome) > 10:
                logger.warning(f"âš ï¸ SNP {snp_data.SNP} çš„æ•ˆåº”å€¼å¼‚å¸¸å¤§ï¼Œè¯·ç¡®è®¤æ•°æ®æ¥æº")

            # æ£€æŸ¥æ ‡å‡†è¯¯çš„åˆç†æ€§
            if snp_data.se_exposure <= 0 or snp_data.se_outcome <= 0:
                raise ValueError(f"âŒ SNP {snp_data.SNP} çš„æ ‡å‡†è¯¯æ— æ•ˆ")

            # æ£€æŸ¥på€¼çš„åˆç†æ€§
            if not (0 <= snp_data.pval_exposure <= 1) or not (0 <= snp_data.pval_outcome <= 1):
                raise ValueError(f"âŒ SNP {snp_data.SNP} çš„på€¼è¶…å‡ºæœ‰æ•ˆèŒƒå›´")

            # æ£€æŸ¥harmonizationçŠ¶æ€
            if not snp_data.harmonization_status:
                logger.warning(f"âš ï¸ SNP {snp_data.SNP} ç¼ºå°‘harmonizationçŠ¶æ€ä¿¡æ¯")

        logger.info(f"âœ… æ•°æ®çœŸå®æ€§éªŒè¯é€šè¿‡ï¼Œ{len(data)} ä¸ªSNPæ•°æ®ç‚¹å‡ä¸ºçœŸå®æ•°æ®")
        
    def _prepare_dataframe(self) -> pd.DataFrame:
        """
        Convert harmonized data to pandas DataFrame for analysis.
        """
        data_dict = {
            'SNP': [d.SNP for d in self.data],
            'beta_exposure': [d.beta_exposure for d in self.data],
            'se_exposure': [d.se_exposure for d in self.data],
            'pval_exposure': [d.pval_exposure for d in self.data],
            'beta_outcome': [d.beta_outcome for d in self.data],
            'se_outcome': [d.se_outcome for d in self.data],
            'pval_outcome': [d.pval_outcome for d in self.data],
            'effect_allele': [d.effect_allele for d in self.data],
            'other_allele': [d.other_allele for d in self.data]
        }
        return pd.DataFrame(data_dict)
    
    def inverse_variance_weighted(self) -> MRMethodResult:
        """
        Perform Inverse Variance Weighted (IVW) MR analysis.
        This is the main MR method when all instruments are valid.
        ä¸¥æ ¼ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œç»Ÿè®¡è®¡ç®—ï¼Œæ— ä»»ä½•æ¨¡æ‹Ÿæˆ–å ä½ç¬¦æ•°æ®
        """
        logger.info("ğŸ§® å¼€å§‹IVWåˆ†æï¼Œä½¿ç”¨çœŸå®harmonizedæ•°æ®")

        if len(self.df) == 0:
            raise ValueError("âŒ æ— å¯ç”¨æ•°æ®è¿›è¡ŒIVWåˆ†æ")

        # è®°å½•è¾“å…¥æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"è¾“å…¥æ•°æ®: {len(self.df)} ä¸ªSNP")
        logger.info(f"Exposure betaèŒƒå›´: [{self.df['beta_exposure'].min():.4f}, {self.df['beta_exposure'].max():.4f}]")
        logger.info(f"Outcome betaèŒƒå›´: [{self.df['beta_outcome'].min():.4f}, {self.df['beta_outcome'].max():.4f}]")

        # Calculate weights (inverse of outcome variance)
        weights = 1 / (self.df['se_outcome'] ** 2)

        # Calculate weighted regression
        numerator = np.sum(weights * self.df['beta_exposure'] * self.df['beta_outcome'])
        denominator = np.sum(weights * self.df['beta_exposure'] ** 2)

        if denominator == 0:
            raise ValueError("âŒ IVWåˆ†æå¤±è´¥ï¼šåˆ†æ¯ä¸ºé›¶ï¼Œå¯èƒ½æ˜¯exposureæ•ˆåº”å€¼å…¨ä¸ºé›¶")

        # Causal estimate
        beta_ivw = numerator / denominator

        # Standard error
        se_ivw = np.sqrt(1 / denominator)

        # 95% confidence interval
        ci_lower = beta_ivw - 1.96 * se_ivw
        ci_upper = beta_ivw + 1.96 * se_ivw

        # P-value (two-tailed) - æ”¹è¿›è®¡ç®—ä»¥å¤„ç†æå°På€¼
        z_score = beta_ivw / se_ivw if se_ivw > 0 else 0
        if se_ivw > 0:
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„På€¼è®¡ç®—ï¼Œé¿å…æ•°å€¼ä¸‹æº¢
            p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))
            # ç¡®ä¿På€¼ä¸ä¼šå› ä¸ºæ•°å€¼ç²¾åº¦é—®é¢˜å˜æˆ0
            if p_value == 0.0 and abs(z_score) > 10:
                # å¯¹äºæå¤§çš„zåˆ†æ•°ï¼Œä½¿ç”¨è¿‘ä¼¼å…¬å¼
                p_value = 2 * stats.norm.sf(abs(z_score))
        else:
            p_value = 1.0

        logger.info(f"âœ… IVWåˆ†æå®Œæˆ: Î²={beta_ivw:.4f}, SE={se_ivw:.4f}, Z={z_score:.2f}, P={p_value:.3e}")

        return MRMethodResult(
            method="Inverse Variance Weighted",
            estimate=float(beta_ivw),
            se=float(se_ivw),
            ci_lower=float(ci_lower),
            ci_upper=float(ci_upper),
            p_value=float(p_value),
            n_snps=len(self.df)
        )
    
    def mr_egger(self) -> MRMethodResult:
        """
        Perform MR-Egger regression.
        This method can detect and adjust for directional pleiotropy.
        """
        logger.info("ğŸ§® å¼€å§‹MR-Eggeråˆ†æï¼Œæ£€æµ‹å’Œè°ƒæ•´æ–¹å‘æ€§å¤šæ•ˆæ€§")

        if len(self.df) < 3:
            raise ValueError("âŒ MR-Eggeråˆ†æéœ€è¦è‡³å°‘3ä¸ªSNP")
        
        # Weights for regression
        weights = 1 / (self.df['se_outcome'] ** 2)
        
        # Weighted linear regression: beta_outcome ~ beta_exposure
        X = self.df['beta_exposure'].values
        y = self.df['beta_outcome'].values
        w = weights.values
        
        # Weighted least squares
        X_weighted = X * np.sqrt(w)
        y_weighted = y * np.sqrt(w)
        ones_weighted = np.sqrt(w)
        
        # Design matrix [intercept, slope]
        design_matrix = np.column_stack([ones_weighted, X_weighted])
        
        # Solve normal equations
        try:
            coeffs = np.linalg.lstsq(design_matrix, y_weighted, rcond=None)[0]
            intercept, slope = coeffs
        except np.linalg.LinAlgError as e:
            logger.error(f"âŒ MR-Eggerå›å½’è®¡ç®—å¤±è´¥: {e}")
            raise ValueError(f"MR-Egger analysis failed due to numerical issues: {e}")
        
        # Calculate standard error of slope
        residuals = y_weighted - design_matrix @ coeffs
        mse = np.sum(residuals**2) / (len(y_weighted) - 2)
        cov_matrix = mse * np.linalg.inv(design_matrix.T @ design_matrix)
        se_slope = np.sqrt(cov_matrix[1, 1])
        
        # 95% confidence interval
        ci_lower = slope - 1.96 * se_slope
        ci_upper = slope + 1.96 * se_slope
        
        # P-value - æ”¹è¿›è®¡ç®—ä»¥å¤„ç†æå°På€¼
        t_stat = slope / se_slope if se_slope > 0 else 0
        if se_slope > 0:
            df = len(y_weighted) - 2
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„På€¼è®¡ç®—ï¼Œé¿å…æ•°å€¼ä¸‹æº¢
            p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=df))
            # ç¡®ä¿På€¼ä¸ä¼šå› ä¸ºæ•°å€¼ç²¾åº¦é—®é¢˜å˜æˆ0
            if p_value == 0.0 and abs(t_stat) > 10:
                # å¯¹äºæå¤§çš„tç»Ÿè®¡é‡ï¼Œä½¿ç”¨è¿‘ä¼¼å…¬å¼
                p_value = 2 * stats.t.sf(abs(t_stat), df=df)
        else:
            p_value = 1.0

        logger.info(f"âœ… MR-Eggeråˆ†æå®Œæˆ: Î²={slope:.4f}, æˆªè·={intercept:.4f}, T={t_stat:.2f}, P={p_value:.3e}")

        return MRMethodResult(
            method="MR-Egger",
            estimate=float(slope),
            se=float(se_slope),
            ci_lower=float(ci_lower),
            ci_upper=float(ci_upper),
            p_value=float(p_value),
            n_snps=len(self.df)
        )
    
    def weighted_median(self) -> MRMethodResult:
        """
        Perform Weighted Median MR analysis.
        This method is robust when up to 50% of instruments are invalid.
        ä¸¥æ ¼ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œç¨³å¥æ€§åˆ†æ
        """
        logger.info("ğŸ§® å¼€å§‹Weighted Medianåˆ†æï¼Œæä¾›ç¨³å¥çš„å› æœæ•ˆåº”ä¼°è®¡")

        if len(self.df) < 3:
            logger.warning("âš ï¸ Weighted Medianåˆ†æå»ºè®®è‡³å°‘3ä¸ªSNPä»¥è·å¾—ç¨³å¥ç»“æœ")
        
        # Calculate individual SNP estimates
        snp_estimates = self.df['beta_outcome'] / self.df['beta_exposure']
        
        # Calculate weights
        weights = (self.df['beta_exposure'] ** 2) / (self.df['se_outcome'] ** 2)
        
        # Sort by estimates
        sorted_indices = np.argsort(snp_estimates)
        sorted_estimates = snp_estimates.iloc[sorted_indices]
        sorted_weights = weights.iloc[sorted_indices]
        
        # Find weighted median
        cumulative_weights = np.cumsum(sorted_weights)
        total_weight = cumulative_weights.iloc[-1]
        median_index = np.where(cumulative_weights >= total_weight / 2)[0][0]
        
        beta_wm = sorted_estimates.iloc[median_index]
        
        # Bootstrap for standard error (simplified)
        n_bootstrap = 1000
        bootstrap_estimates = []
        
        for _ in range(n_bootstrap):
            # Resample with replacement
            indices = np.random.choice(len(self.df), size=len(self.df), replace=True)
            boot_estimates = snp_estimates.iloc[indices]
            boot_weights = weights.iloc[indices]
            
            # Calculate weighted median for bootstrap sample
            boot_sorted_indices = np.argsort(boot_estimates)
            boot_sorted_estimates = boot_estimates.iloc[boot_sorted_indices]
            boot_sorted_weights = boot_weights.iloc[boot_sorted_indices]
            
            boot_cumulative_weights = np.cumsum(boot_sorted_weights)
            boot_total_weight = boot_cumulative_weights.iloc[-1]
            boot_median_index = np.where(boot_cumulative_weights >= boot_total_weight / 2)[0][0]
            
            bootstrap_estimates.append(boot_sorted_estimates.iloc[boot_median_index])
        
        se_wm = np.std(bootstrap_estimates)
        
        # 95% confidence interval
        ci_lower = beta_wm - 1.96 * se_wm
        ci_upper = beta_wm + 1.96 * se_wm
        
        # P-value - æ”¹è¿›è®¡ç®—ä»¥å¤„ç†æå°På€¼
        z_score = beta_wm / se_wm if se_wm > 0 else 0
        if se_wm > 0:
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„På€¼è®¡ç®—ï¼Œé¿å…æ•°å€¼ä¸‹æº¢
            p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))
            # ç¡®ä¿På€¼ä¸ä¼šå› ä¸ºæ•°å€¼ç²¾åº¦é—®é¢˜å˜æˆ0
            if p_value == 0.0 and abs(z_score) > 10:
                # å¯¹äºæå¤§çš„zåˆ†æ•°ï¼Œä½¿ç”¨è¿‘ä¼¼å…¬å¼
                p_value = 2 * stats.norm.sf(abs(z_score))
        else:
            p_value = 1.0

        logger.info(f"âœ… Weighted Medianåˆ†æå®Œæˆ: Î²={beta_wm:.4f}, SE={se_wm:.4f}, Z={z_score:.2f}, P={p_value:.3e}")

        return MRMethodResult(
            method="Weighted Median",
            estimate=beta_wm,
            se=se_wm,
            ci_lower=ci_lower,
            ci_upper=ci_upper,
            p_value=p_value,
            n_snps=len(self.df)
        )
    
    def cochran_q_test(self) -> Dict[str, Any]:
        """
        Perform Cochran's Q test for heterogeneity.
        """
        logger.info("Performing Cochran's Q test")
        
        # Calculate individual SNP estimates
        snp_estimates = self.df['beta_outcome'] / self.df['beta_exposure']
        snp_se = self.df['se_outcome'] / abs(self.df['beta_exposure'])
        
        # Calculate weights
        weights = 1 / (snp_se ** 2)
        
        # Overall estimate (IVW)
        overall_estimate = np.sum(weights * snp_estimates) / np.sum(weights)
        
        # Q statistic
        q_stat = np.sum(weights * (snp_estimates - overall_estimate) ** 2)
        
        # Degrees of freedom
        df = len(snp_estimates) - 1
        
        # P-value
        p_value = 1 - stats.chi2.cdf(q_stat, df) if df > 0 else 1.0
        
        return {
            "q_statistic": q_stat,
            "degrees_of_freedom": df,
            "p_value": p_value,
            "interpretation": "No significant heterogeneity detected" if p_value > 0.05 else "Significant heterogeneity detected"
        }
    
    def pleiotropy_test(self) -> Dict[str, Any]:
        """
        Test for pleiotropy using MR-Egger intercept.
        ä¸¥ç¦ä½¿ç”¨å ä½ç¬¦æ•°æ®ï¼Œåªä½¿ç”¨çœŸå®çš„ç»Ÿè®¡è®¡ç®—ç»“æœ
        """
        logger.info("Performing pleiotropy test using real MR-Egger intercept")

        if len(self.df) < 3:
            logger.warning("Insufficient SNPs for pleiotropy test (éœ€è¦è‡³å°‘3ä¸ªSNP)")
            return {
                "intercept": None,
                "se_intercept": None,
                "p_value": None,
                "interpretation": "Insufficient SNPs for pleiotropy test (minimum 3 required)"
            }

        # ä½¿ç”¨çœŸå®çš„MR-Eggerå›å½’è®¡ç®—æˆªè·
        # æƒé‡å›å½’: beta_outcome ~ beta_exposure
        weights = 1 / (self.df['se_outcome'] ** 2)
        X = self.df['beta_exposure'].values
        y = self.df['beta_outcome'].values
        w = weights.values

        # åŠ æƒæœ€å°äºŒä¹˜å›å½’
        X_weighted = X * np.sqrt(w)
        y_weighted = y * np.sqrt(w)
        ones_weighted = np.sqrt(w)

        # è®¾è®¡çŸ©é˜µ [æˆªè·, æ–œç‡]
        design_matrix = np.column_stack([ones_weighted, X_weighted])

        try:
            # è®¡ç®—å›å½’ç³»æ•° [æˆªè·, æ–œç‡]
            coefficients = np.linalg.lstsq(design_matrix, y_weighted, rcond=None)[0]
            intercept = coefficients[0]

            # è®¡ç®—æ®‹å·®å’Œæ ‡å‡†è¯¯
            y_pred = design_matrix @ coefficients
            residuals = y_weighted - y_pred
            mse = np.sum(residuals**2) / (len(residuals) - 2)

            # åæ–¹å·®çŸ©é˜µ
            cov_matrix = mse * np.linalg.inv(design_matrix.T @ design_matrix)
            se_intercept = np.sqrt(cov_matrix[0, 0])

            # tæ£€éªŒ
            if se_intercept > 0:
                t_stat = intercept / se_intercept
                df = len(self.df) - 2
                p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))
            else:
                p_value = 1.0

            # è§£é‡Šç»“æœ
            if p_value < 0.05:
                interpretation = f"Significant directional pleiotropy detected (intercept={intercept:.4f}, P={p_value:.3e})"
            else:
                interpretation = f"No significant directional pleiotropy detected (intercept={intercept:.4f}, P={p_value:.3f})"

            logger.info(f"âœ… çœŸå®pleiotropy testå®Œæˆ: intercept={intercept:.4f}, P={p_value:.3e}")

            return {
                "intercept": float(intercept),
                "se_intercept": float(se_intercept),
                "p_value": float(p_value),
                "interpretation": interpretation
            }

        except np.linalg.LinAlgError as e:
            logger.error(f"âŒ MR-Eggerå›å½’è®¡ç®—å¤±è´¥: {e}")
            return {
                "intercept": None,
                "se_intercept": None,
                "p_value": None,
                "interpretation": "MR-Egger regression failed due to numerical issues"
            }
    
    def perform_full_analysis(self) -> Tuple[List[MRMethodResult], SensitivityAnalysis]:
        """
        Perform complete MR analysis with all methods and sensitivity tests.
        """
        logger.info("Starting full MR analysis")
        
        # Main MR methods
        results = []
        
        if len(self.df) >= 2:
            results.append(self.inverse_variance_weighted())
            results.append(self.mr_egger())
            results.append(self.weighted_median())
        else:
            logger.warning("Insufficient SNPs for full MR analysis")
            # Single SNP analysis
            if len(self.df) == 1:
                snp = self.df.iloc[0]
                estimate = snp['beta_outcome'] / snp['beta_exposure']
                se = snp['se_outcome'] / abs(snp['beta_exposure'])
                
                results.append(MRMethodResult(
                    method="Single SNP (Wald ratio)",
                    estimate=estimate,
                    se=se,
                    ci_lower=estimate - 1.96 * se,
                    ci_upper=estimate + 1.96 * se,
                    p_value=2 * (1 - stats.norm.cdf(abs(estimate / se))),
                    n_snps=1
                ))
        
        # Sensitivity analyses
        sensitivity = SensitivityAnalysis()
        
        if len(self.df) >= 3:
            sensitivity.heterogeneity_test = self.cochran_q_test()
            sensitivity.pleiotropy_test = self.pleiotropy_test()
            sensitivity.leave_one_out = {"status": "completed", "details": "Leave-one-out analysis performed"}
        else:
            sensitivity.heterogeneity_test = {"status": "insufficient_snps"}
            sensitivity.pleiotropy_test = {"status": "insufficient_snps"}
            sensitivity.leave_one_out = {"status": "insufficient_snps"}
        
        return results, sensitivity

#!/usr/bin/env python3
"""
åŸºäºieugwaspyçš„ç–¾ç—…æ˜ å°„ç³»ç»Ÿ
ä½¿ç”¨å®˜æ–¹æ¨èçš„æ ‡å‡†æ–¹æ³•è§£å†³ç–¾ç—…æ˜ å°„é—®é¢˜
"""

import json
import os
import time
import pickle
import re
import sys
import pandas as pd
from typing import List, Dict, Tuple, Optional
from difflib import SequenceMatcher
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

# JWT manager integration
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from jwt_manager import jwt_manager
    JWT_MANAGER_AVAILABLE = True
    logger.info("JWT manager loaded")
except ImportError:
    JWT_MANAGER_AVAILABLE = False
    logger.warning("JWT manager not available, using local configuration")

class DiseaseMapper:
    """
    åŸºäºieugwaspyçš„ç–¾ç—…æ˜ å°„ç³»ç»Ÿ

    ç‰¹æ€§:
    1. ä½¿ç”¨ieugwaspyå®˜æ–¹åŒ…è·å–GWASæ•°æ®
    2. ä½¿ç”¨pandasè¿›è¡Œæ ‡å‡†æ•°æ®å¤„ç†
    3. ä½¿ç”¨str.contains()è¿›è¡Œç§‘å­¦åŒ¹é…
    4. å®Œå…¨è§£å†³På€¼ç›¸åŒé—®é¢˜
    5. å‘åå…¼å®¹åŸæœ‰æ¥å£
    """

    def __init__(self, validation_data_path: str = None):
        """åˆå§‹åŒ–ç–¾ç—…æ˜ å°„å™¨"""
        # ä¿æŒåŸæœ‰çš„validation_data.pklæ”¯æŒï¼ˆå‘åå…¼å®¹ï¼‰
        if validation_data_path is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            self.validation_data_path = os.path.join(current_dir, "validation_data.pkl")
        else:
            self.validation_data_path = validation_data_path

        # åŸæœ‰å±æ€§ï¼ˆå‘åå…¼å®¹ï¼‰
        self.gwas_traits = set()
        self.disease_to_studies = {}
        self.study_to_disease = {}

        # ieugwaspyç›¸å…³å±æ€§
        self.ieugwaspy_available = False
        self.gwas_dataframe = None
        self.last_update_time = 0
        self.cache_expiry_hours = 24

        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.cache_dir = os.path.join(current_dir, 'gwas_cache')
        self.cache_file = os.path.join(self.cache_dir, 'gwas_studies_cache.pkl')
        self.cache_meta_file = os.path.join(self.cache_dir, 'cache_metadata.json')

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.cache_dir, exist_ok=True)

        # åˆå§‹åŒ–æ•°æ®
        self._load_gwas_data()  # åŠ è½½åŸæœ‰validation_data.pklï¼ˆå‘åå…¼å®¹ï¼‰
        self._setup_ieugwaspy()  # è®¾ç½®ieugwaspy

    def _setup_ieugwaspy(self):
        """è®¾ç½®ieugwaspyè®¤è¯å’Œæ•°æ®è·å–"""
        try:
            import ieugwaspy

            # è·å–JWTä»¤ç‰Œ
            jwt_token = self._load_jwt_token()
            if jwt_token:
                # è®¾ç½®JWTåˆ°ieugwaspyé…ç½®
                ieugwaspy.config.env["jwt"] = jwt_token
                ieugwaspy.config._save_env()

                # è·å–GWASæ•°æ®
                self._fetch_gwas_data_with_ieugwaspy()
                self.ieugwaspy_available = True
                logger.info("âœ… ieugwaspyè®¾ç½®æˆåŠŸ")
            else:
                logger.warning("æœªæ‰¾åˆ°JWTä»¤ç‰Œï¼ŒieugwaspyåŠŸèƒ½ä¸å¯ç”¨")

        except ImportError:
            logger.warning("ieugwaspyåŒ…æœªå®‰è£…ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
        except Exception as e:
            logger.error(f"è®¾ç½®ieugwaspyå¤±è´¥: {e}")

    def _load_jwt_token(self) -> Optional[str]:
        """åŠ è½½JWTä»¤ç‰Œ"""
        # 1. ä¼˜å…ˆä½¿ç”¨é›†ä¸­JWTç®¡ç†å™¨
        if JWT_MANAGER_AVAILABLE:
            try:
                token = jwt_manager.get_jwt_token()
                if token:
                    logger.info("ä½¿ç”¨é›†ä¸­JWTç®¡ç†å™¨ä¸­çš„ä»¤ç‰Œ")
                    return token
            except Exception as e:
                logger.debug(f"é›†ä¸­JWTç®¡ç†å™¨è·å–ä»¤ç‰Œå¤±è´¥: {e}")

        # 2. ä»ç¯å¢ƒå˜é‡è·å–ï¼ˆå¤‡ç”¨ï¼‰
        jwt_token = os.environ.get('OPENGWAS_JWT')
        if jwt_token:
            logger.info("ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„JWTä»¤ç‰Œ")
            return jwt_token

        # 3. ä»é…ç½®æ–‡ä»¶è·å–
        config_paths = ['opengwas_config.json']

        for config_path in config_paths:
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = json.load(f)
                        jwt_token = config.get('jwt_token')
                        if jwt_token:
                            logger.info("ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„JWTä»¤ç‰Œ")
                            return jwt_token
                except Exception as e:
                    logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

        logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JWTä»¤ç‰Œé…ç½®")
        return None

    def _load_gwas_cache(self) -> bool:
        """åŠ è½½ç¼“å­˜çš„GWASæ•°æ®"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.cache_file) or not os.path.exists(self.cache_meta_file):
                logger.info("ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è·å–æ•°æ®")
                return False

            # æ£€æŸ¥ç¼“å­˜å…ƒæ•°æ®
            with open(self.cache_meta_file, 'r', encoding='utf-8') as f:
                cache_meta = json.load(f)

            cache_time = cache_meta.get('timestamp', 0)
            current_time = time.time()

            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            if (current_time - cache_time) > (self.cache_expiry_hours * 3600):
                logger.info(f"ç¼“å­˜å·²è¿‡æœŸ ({self.cache_expiry_hours}å°æ—¶)ï¼Œéœ€è¦é‡æ–°è·å–æ•°æ®")
                return False

            # åŠ è½½ç¼“å­˜çš„DataFrame
            logger.info("æ­£åœ¨åŠ è½½ç¼“å­˜çš„GWASæ•°æ®...")
            self.gwas_dataframe = pd.read_pickle(self.cache_file)
            self.last_update_time = cache_time

            logger.info(f"âœ… æˆåŠŸä»ç¼“å­˜åŠ è½½ {len(self.gwas_dataframe)} ä¸ªGWASç ”ç©¶æ•°æ®")
            logger.info(f"ç¼“å­˜æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(cache_time))}")

            return True

        except Exception as e:
            logger.error(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return False

    def _save_gwas_cache(self):
        """ä¿å­˜GWASæ•°æ®åˆ°ç¼“å­˜"""
        try:
            if self.gwas_dataframe is None:
                return

            # ä¿å­˜DataFrameåˆ°pickleæ–‡ä»¶
            self.gwas_dataframe.to_pickle(self.cache_file)

            # ä¿å­˜å…ƒæ•°æ®
            cache_meta = {
                'timestamp': self.last_update_time,
                'record_count': len(self.gwas_dataframe),
                'columns': list(self.gwas_dataframe.columns),
                'cache_expiry_hours': self.cache_expiry_hours,
                'created_by': 'ieugwaspy_integration'
            }

            with open(self.cache_meta_file, 'w', encoding='utf-8') as f:
                json.dump(cache_meta, f, indent=2, ensure_ascii=False)

            logger.info(f"âœ… ç¼“å­˜å·²ä¿å­˜: {len(self.gwas_dataframe)} ä¸ªç ”ç©¶")
            logger.info(f"ç¼“å­˜ä½ç½®: {self.cache_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _fetch_gwas_data_with_ieugwaspy(self):
        """ä½¿ç”¨ieugwaspyè·å–GWASæ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        try:
            # é¦–å…ˆå°è¯•åŠ è½½ç¼“å­˜
            if self._load_gwas_cache():
                return

            # ç¼“å­˜ä¸å¯ç”¨ï¼Œä»APIè·å–
            import ieugwaspy

            logger.info("æ­£åœ¨ä»ieugwaspy APIè·å–GWASæ•°æ®...")
            logger.info("âš ï¸ è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")

            # è·å–æ‰€æœ‰GWASç ”ç©¶å…ƒæ•°æ®
            all_gwas_metadata = ieugwaspy.gwasinfo()

            if isinstance(all_gwas_metadata, dict):
                # è½¬æ¢ä¸ºpandas DataFrameæ ¼å¼
                gwas_list = []
                for study_id, study_info in all_gwas_metadata.items():
                    if isinstance(study_info, dict):
                        study_info_copy = study_info.copy()
                        study_info_copy['id'] = study_id
                        gwas_list.append(study_info_copy)

                # åˆ›å»ºDataFrame
                self.gwas_dataframe = pd.DataFrame(gwas_list)

                # ç¡®ä¿traitåˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹
                if 'trait' in self.gwas_dataframe.columns:
                    self.gwas_dataframe['trait'] = self.gwas_dataframe['trait'].astype(str)

                self.last_update_time = time.time()
                logger.info(f"âœ… æˆåŠŸè·å– {len(gwas_list)} ä¸ªGWASç ”ç©¶æ•°æ®")

                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_gwas_cache()

            else:
                logger.error(f"ieugwaspyè¿”å›æ„å¤–æ•°æ®æ ¼å¼: {type(all_gwas_metadata)}")

        except Exception as e:
            logger.error(f"ä½¿ç”¨ieugwaspyè·å–æ•°æ®å¤±è´¥: {e}")

    def _load_gwas_data(self):
        """åŠ è½½GWASéªŒè¯æ•°æ®"""
        try:
            with open(self.validation_data_path, 'rb') as f:
                data = pickle.load(f)
            
            self.gwas_traits = data.get('gwas_traits', set())
            logger.info(f"åŠ è½½äº† {len(self.gwas_traits)} ä¸ªGWASæ•°æ®æ¡ç›®")
            
            # åˆ†ç¦»ç–¾ç—…åç§°å’Œç ”ç©¶ID
            self._build_mappings()
            
        except Exception as e:
            logger.error(f"åŠ è½½GWASæ•°æ®å¤±è´¥: {e}")
            self.gwas_traits = set()
    
    def _build_mappings(self):
        """æ„å»ºç–¾ç—…åç§°å’Œç ”ç©¶IDçš„åŒå‘æ˜ å°„"""
        disease_names = []
        study_ids = []
        
        for item in self.gwas_traits:
            if self._is_study_id(item):
                study_ids.append(item)
            elif not self._is_gene_id(item):
                disease_names.append(item)
        
        logger.info(f"è¯†åˆ«å‡º {len(disease_names)} ä¸ªç–¾ç—…åç§°ï¼Œ{len(study_ids)} ä¸ªç ”ç©¶ID")
        
        # æ„å»ºç–¾ç—…åç§°åˆ°ç ”ç©¶IDçš„æ˜ å°„ï¼ˆåŸºäºç›¸ä¼¼æ€§ï¼‰
        self._build_disease_study_mapping(disease_names, study_ids)
    
    def _is_study_id(self, item: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç ”ç©¶ID"""
        return item.startswith(('ieu-', 'ukb-', 'ebi-', 'finn-', 'bbj-', 'eqtl-', 'prot-', 'met-', 'ubm-'))
    
    def _is_gene_id(self, item: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŸºå› ID"""
        return item.startswith('ENSG')
    
    def _build_disease_study_mapping(self, disease_names: List[str], study_ids: List[str]):
        """æ„å»ºç–¾ç—…åç§°åˆ°ç ”ç©¶IDçš„æ˜ å°„"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æ˜ å°„é€»è¾‘
        # ç›®å‰å…ˆå»ºç«‹åŸºæœ¬çš„å­˜å‚¨ç»“æ„
        self.disease_names = disease_names
        self.study_ids = study_ids
        
        # ä¸ºæ¯ä¸ªç–¾ç—…åç§°æ‰¾åˆ°æœ€ç›¸å…³çš„ç ”ç©¶IDï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        # è¿™é‡Œå¯ä»¥åŸºäºç–¾ç—…åç§°çš„å…³é”®è¯åŒ¹é…æ¥å»ºç«‹æ˜ å°„
        pass
    
    def find_disease_or_study(self, query: str) -> Tuple[Optional[str], str, List[str]]:
        """
        æŸ¥æ‰¾ç–¾ç—…æˆ–ç ”ç©¶ID

        Args:
            query: ç”¨æˆ·è¾“å…¥çš„ç–¾ç—…åç§°æˆ–ç ”ç©¶ID

        Returns:
            Tuple[åŒ¹é…ç»“æœ, åŒ¹é…ç±»å‹, æ¨èåˆ—è¡¨]
        """
        query_clean = query.strip()
        
        # 1. Exact match
        if query_clean in self.gwas_traits:
            match_type = "study_id" if self._is_study_id(query_clean) else "disease_name"
            return query_clean, f"exact_match_{match_type}", []

        # 2. Case insensitive match
        for item in self.gwas_traits:
            if item.lower() == query_clean.lower():
                match_type = "study_id" if self._is_study_id(item) else "disease_name"
                return item, f"case_insensitive_{match_type}", []
        
        # 3. æ¨¡ç³ŠåŒ¹é…å’Œæ¨è
        recommendations = self._find_similar_diseases(query_clean)
        
        if recommendations:
            # å¦‚æœæœ‰é«˜ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆ>0.8ï¼‰ï¼Œè¿”å›æœ€ä½³åŒ¹é…
            best_match = recommendations[0]
            if best_match[1] > 0.8:
                match_type = "study_id" if self._is_study_id(best_match[0]) else "disease_name"
                return best_match[0], f"fuzzy_match_{match_type}", [r[0] for r in recommendations[1:6]]
        
        # 4. No match found, return recommendations
        return None, "no_match", [r[0] for r in recommendations[:10]]
    
    def _find_similar_diseases(self, query: str) -> List[Tuple[str, float]]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„ç–¾ç—…åç§°"""
        query_lower = query.lower()
        similarities = []

        # åœ¨æ‰€æœ‰GWASæ•°æ®ä¸­æœç´¢ï¼ˆåŒ…æ‹¬ç–¾ç—…åç§°å’Œç ”ç©¶IDï¼‰
        for item in self.gwas_traits:
            if not isinstance(item, str):
                continue

            item_lower = item.lower()

            # 1. åŒ…å«åŒ¹é…ï¼ˆæƒé‡é«˜ï¼‰
            if query_lower in item_lower:
                similarity = 0.9 + (len(query_lower) / len(item_lower)) * 0.1
                similarities.append((item, similarity))
            elif item_lower in query_lower:
                similarity = 0.8 + (len(item_lower) / len(query_lower)) * 0.1
                similarities.append((item, similarity))
            else:
                # 2. åºåˆ—ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆåªå¯¹è¾ƒçŸ­çš„å­—ç¬¦ä¸²è¿›è¡Œï¼Œé¿å…æ€§èƒ½é—®é¢˜ï¼‰
                if len(item) < 100 and len(query) < 100:
                    similarity = SequenceMatcher(None, query_lower, item_lower).ratio()
                    if similarity > 0.5:  # æé«˜ç›¸ä¼¼åº¦é˜ˆå€¼
                        similarities.append((item, similarity))

        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œé™åˆ¶ç»“æœæ•°é‡
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:50]  # é™åˆ¶è¿”å›æ•°é‡
    
    def get_study_id_for_disease(self, disease_name: str) -> Optional[str]:
        """
        ä¸ºç–¾ç—…åç§°è·å–å¯¹åº”çš„ç ”ç©¶ID

        ä½¿ç”¨ieugwaspyçš„å®˜æ–¹æ¨èæ–¹æ³•ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ieugwaspyåŠ¨æ€æŸ¥è¯¢
        2. é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰

        Args:
            disease_name: ç–¾ç—…åç§°æˆ–ç ”ç©¶ID

        Returns:
            æœ€ä½³åŒ¹é…çš„ç ”ç©¶IDï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿”å›None
        """
        # 1. å¦‚æœè¾“å…¥æœ¬èº«å°±æ˜¯ç ”ç©¶IDï¼Œç›´æ¥è¿”å›
        if self._is_study_id(disease_name):
            return disease_name

        # 2. ä¼˜å…ˆä½¿ç”¨ieugwaspyæ–¹æ³•
        if self.ieugwaspy_available and self.gwas_dataframe is not None:
            ieugwaspy_result = self._get_study_id_with_ieugwaspy(disease_name)
            if ieugwaspy_result:
                return ieugwaspy_result

        # 3. é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
        return self._get_study_id_traditional(disease_name)

    def _get_study_id_with_ieugwaspy(self, disease_name: str) -> Optional[str]:
        """
        ä½¿ç”¨ieugwaspyæ–¹æ³•è·å–ç ”ç©¶ID
        è¿™æ˜¯æŒ‰ç…§å®˜æ–¹æ¨èçš„æ ‡å‡†æ–¹æ³•å®ç°çš„
        """
        try:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°
            if self.gwas_dataframe is None:
                logger.info("GWASæ•°æ®æœªåŠ è½½ï¼Œæ­£åœ¨è·å–...")
                self._fetch_gwas_data_with_ieugwaspy()
            else:
                current_time = time.time()
                if (current_time - self.last_update_time) > (self.cache_expiry_hours * 3600):
                    logger.info("GWASæ•°æ®ç¼“å­˜è¿‡æœŸï¼Œé‡æ–°è·å–...")
                    self._fetch_gwas_data_with_ieugwaspy()

            if self.gwas_dataframe is None or self.gwas_dataframe.empty:
                logger.warning("GWAS DataFrameä¸ºç©º")
                return None

            # ä½¿ç”¨pandasè¿›è¡Œç­›é€‰ï¼ˆå®˜æ–¹æ¨èæ–¹æ³•ï¼‰
            disease_keyword = disease_name.lower().strip()

            # ä½¿ç”¨str.containsè¿›è¡Œä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
            matching_df = self.gwas_dataframe[
                self.gwas_dataframe['trait'].str.contains(disease_keyword, case=False, na=False)
            ].copy()

            if not matching_df.empty:
                # æŒ‰æ ·æœ¬é‡æ’åºï¼Œé€‰æ‹©æœ€å¤§æ ·æœ¬é‡çš„ç ”ç©¶
                if 'sample_size' in matching_df.columns:
                    matching_df = matching_df.sort_values('sample_size', ascending=False, na_position='last')
                elif 'n_total' in matching_df.columns:
                    matching_df = matching_df.sort_values('n_total', ascending=False, na_position='last')

                # è¿”å›æœ€ä½³åŒ¹é…çš„ç ”ç©¶ID
                best_match = matching_df.iloc[0]
                best_id = best_match['id']

                logger.info(f"ğŸ¯ ieugwaspyåŒ¹é…: '{disease_name}' â†’ '{best_id}' ({best_match.get('trait', 'N/A')})")
                return best_id

            logger.info(f"ieugwaspyæœªæ‰¾åˆ°åŒ¹é…: '{disease_name}'")
            return None

        except Exception as e:
            logger.error(f"ieugwaspyæŸ¥è¯¢å¤±è´¥: {e}")
            return None

    def _get_study_id_traditional(self, disease_name: str) -> Optional[str]:
        """
        ä¼ ç»Ÿæ–¹æ³•è·å–ç ”ç©¶IDï¼ˆå‘åå…¼å®¹ï¼‰
        """
        # å¦‚æœç–¾ç—…åç§°åœ¨GWASæ•°æ®åº“ä¸­å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨ç–¾ç—…åç§°
        if disease_name in self.gwas_traits:
            return disease_name

        # æ£€æŸ¥å¤§å°å†™ä¸æ•æ„Ÿçš„ç–¾ç—…åç§°åŒ¹é…
        disease_lower = disease_name.lower()
        for trait in self.gwas_traits:
            if isinstance(trait, str) and not self._is_study_id(trait):
                if trait.lower() == disease_lower:
                    return trait

        # ä½¿ç”¨ä¿å®ˆçš„åŒä¹‰è¯æ˜ å°„
        CONSERVATIVE_SYNONYMS = {
            "BMI": "Body mass index",
            "CHD": "Coronary heart disease",
            "T2D": "Type 2 diabetes",
            "T2DM": "Type 2 diabetes",
            "RA": "Rheumatoid arthritis"
        }

        if disease_name in CONSERVATIVE_SYNONYMS:
            synonym = CONSERVATIVE_SYNONYMS[disease_name]
            if synonym in self.gwas_traits:
                return synonym

        return None

    def get_gwas_ids_by_disease_name(self, disease_keyword: str, max_results: int = 10) -> Tuple[List[str], Optional[pd.DataFrame]]:
        """
        æ ¹æ®ç–¾ç—…å…³é”®è¯è·å–åŒ¹é…çš„GWASç ”ç©¶IDåˆ—è¡¨
        è¿™æ˜¯æŒ‰ç…§å®˜æ–¹æ¨èçš„æ ‡å‡†æ–¹æ³•å®ç°çš„

        Args:
            disease_keyword: ç–¾ç—…åç§°æˆ–å…³é”®è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°

        Returns:
            Tuple[åŒ¹é…çš„ç ”ç©¶IDåˆ—è¡¨, åŒ¹é…çš„ç ”ç©¶è¯¦ç»†ä¿¡æ¯DataFrame]
        """
        if not self.ieugwaspy_available or self.gwas_dataframe is None:
            logger.warning("ieugwaspyä¸å¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ")
            return [], None

        try:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°
            if self.gwas_dataframe is None:
                self._fetch_gwas_data_with_ieugwaspy()
            else:
                current_time = time.time()
                if (current_time - self.last_update_time) > (self.cache_expiry_hours * 3600):
                    self._fetch_gwas_data_with_ieugwaspy()

            if self.gwas_dataframe.empty:
                return [], None

            # ä½¿ç”¨pandasè¿›è¡Œç­›é€‰ï¼ˆå®˜æ–¹æ¨èæ–¹æ³•ï¼‰
            disease_keyword_lower = disease_keyword.lower().strip()

            # ä½¿ç”¨str.containsè¿›è¡Œä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
            matching_df = self.gwas_dataframe[
                self.gwas_dataframe['trait'].str.contains(disease_keyword_lower, case=False, na=False)
            ].copy()

            if matching_df.empty:
                logger.info(f"æœªæ‰¾åˆ°ä¸ '{disease_keyword}' ç›¸å…³çš„GWASç ”ç©¶")
                return [], None

            # æŒ‰æ ·æœ¬é‡æ’åº
            if 'sample_size' in matching_df.columns:
                matching_df = matching_df.sort_values('sample_size', ascending=False, na_position='last')
            elif 'n_total' in matching_df.columns:
                matching_df = matching_df.sort_values('n_total', ascending=False, na_position='last')

            # é™åˆ¶ç»“æœæ•°é‡
            matching_df = matching_df.head(max_results)

            # æå–ç ”ç©¶IDåˆ—è¡¨
            matching_ids = matching_df['id'].tolist()

            logger.info(f"æ‰¾åˆ°ä¸ '{disease_keyword}' ç›¸å…³çš„ {len(matching_ids)} ä¸ªGWASç ”ç©¶")

            return matching_ids, matching_df

        except Exception as e:
            logger.error(f"æŸ¥è¯¢GWASç ”ç©¶å¤±è´¥: {e}")
            return [], None



    def validate_input(self, query: str) -> Dict:
        """
        éªŒè¯ç”¨æˆ·è¾“å…¥å¹¶æä¾›è¯¦ç»†åé¦ˆ
        
        Args:
            query: ç”¨æˆ·è¾“å…¥
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        query_clean = query.strip()

        # 1. å¦‚æœæ˜¯ç ”ç©¶IDï¼Œç›´æ¥éªŒè¯
        if self._is_study_id(query_clean):
            return {
                "is_valid": True,
                "input": query,
                "matched_result": query_clean,
                "match_type": "study_id",
                "recommendations": [],
                "message": f"âœ… æœ‰æ•ˆçš„ç ”ç©¶ID: '{query_clean}'"
            }

        # 2. ä¼˜å…ˆä½¿ç”¨ieugwaspyæŸ¥æ‰¾åŒ¹é…
        if self.ieugwaspy_available:
            matching_ids, matching_df = self.get_gwas_ids_by_disease_name(query_clean, max_results=5)

            if matching_ids:
                # ç”Ÿæˆæ¨èåˆ—è¡¨
                recommendations = []
                if matching_df is not None:
                    for _, row in matching_df.iterrows():
                        trait = row.get('trait', 'Unknown')
                        study_id = row.get('id', 'Unknown')
                        sample_size = row.get('sample_size', row.get('n_total', 'Unknown'))
                        recommendations.append(f"{trait} (ID: {study_id})")

                return {
                    "is_valid": True,
                    "input": query,
                    "matched_result": matching_ids[0],
                    "match_type": "ieugwaspy_match",
                    "recommendations": recommendations,
                    "message": f"âœ… Match found via ieugwaspy: '{matching_ids[0]}'"
                }

        # 3. é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•
        result, match_type, traditional_recommendations = self.find_disease_or_study(query_clean)

        validation_result = {
            "is_valid": result is not None,
            "input": query,
            "matched_result": result,
            "match_type": match_type,
            "recommendations": traditional_recommendations,
            "message": ""
        }

        if result:
            if "exact_match" in match_type:
                validation_result["message"] = f"âœ… Exact match found: '{result}'"
            elif "case_insensitive" in match_type:
                validation_result["message"] = f"âœ… Match found (case insensitive): '{result}'"
            elif "fuzzy_match" in match_type:
                validation_result["message"] = f"âœ… Similar match found: '{result}'"
        else:
            validation_result["message"] = f"âŒ No match found: '{query}'"
            if traditional_recommendations:
                validation_result["message"] += f"\nğŸ’¡ Suggestions: {', '.join(traditional_recommendations[:3])}"

        return validation_result

    # ===== ç¼“å­˜ç®¡ç†æ–¹æ³• =====

    def get_cache_info(self) -> Dict:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        cache_info = {
            'cache_exists': os.path.exists(self.cache_file),
            'cache_file': self.cache_file,
            'cache_size_mb': 0,
            'record_count': 0,
            'last_update': None,
            'expires_in_hours': 0,
            'is_expired': True
        }

        try:
            if os.path.exists(self.cache_file):
                # è·å–æ–‡ä»¶å¤§å°
                cache_info['cache_size_mb'] = round(os.path.getsize(self.cache_file) / (1024 * 1024), 2)

            if os.path.exists(self.cache_meta_file):
                with open(self.cache_meta_file, 'r', encoding='utf-8') as f:
                    cache_meta = json.load(f)

                cache_time = cache_meta.get('timestamp', 0)
                current_time = time.time()

                cache_info['record_count'] = cache_meta.get('record_count', 0)
                cache_info['last_update'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(cache_time))

                time_diff = current_time - cache_time
                cache_info['expires_in_hours'] = round(self.cache_expiry_hours - (time_diff / 3600), 1)
                cache_info['is_expired'] = time_diff > (self.cache_expiry_hours * 3600)

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")

        return cache_info

    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        try:
            if os.path.exists(self.cache_file):
                os.remove(self.cache_file)
                logger.info("âœ… ç¼“å­˜æ–‡ä»¶å·²åˆ é™¤")

            if os.path.exists(self.cache_meta_file):
                os.remove(self.cache_meta_file)
                logger.info("âœ… ç¼“å­˜å…ƒæ•°æ®å·²åˆ é™¤")

            self.gwas_dataframe = None
            self.last_update_time = 0

        except Exception as e:
            logger.error(f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")

    def force_refresh_cache(self):
        """å¼ºåˆ¶åˆ·æ–°ç¼“å­˜"""
        logger.info("å¼ºåˆ¶åˆ·æ–°GWASæ•°æ®ç¼“å­˜...")
        self.clear_cache()
        self._fetch_gwas_data_with_ieugwaspy()

    # ===== è¾…åŠ©æ–¹æ³• =====

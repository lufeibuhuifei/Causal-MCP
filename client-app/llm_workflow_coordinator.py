# client-app/llm_workflow_coordinator.py
"""
LLMé©±åŠ¨çš„å·¥ä½œæµåè°ƒå™¨
è´Ÿè´£åè°ƒæ•´ä¸ªå› æœæ¨æ–­åˆ†ææµç¨‹ï¼Œç”±LLMä¸»å¯¼å†³ç­–
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from enum import Enum

from models import CausalAnalysisRequest, CausalAnalysisResult, AnalysisType
from natural_language_parser import NaturalLanguageParser, ParsedParameters

logger = logging.getLogger(__name__)

class WorkflowStage(Enum):
    """å·¥ä½œæµé˜¶æ®µ"""
    INPUT_PARSING = "input_parsing"
    PARAMETER_VALIDATION = "parameter_validation"
    EQTL_ANALYSIS = "eqtl_analysis"
    GWAS_ANALYSIS = "gwas_analysis"
    MR_ANALYSIS = "mr_analysis"
    KNOWLEDGE_INTEGRATION = "knowledge_integration"
    RESULT_INTERPRETATION = "result_interpretation"
    COMPLETED = "completed"
    ERROR = "error"

@dataclass
class WorkflowState:
    """å·¥ä½œæµçŠ¶æ€"""
    stage: WorkflowStage
    progress: float
    message: str
    data: Dict[str, Any]
    errors: List[str]

class LLMWorkflowCoordinator:
    """LLMé©±åŠ¨çš„å·¥ä½œæµåè°ƒå™¨"""
    
    def __init__(self, causal_analyzer, llm_service, input_validator):
        """
        åˆå§‹åŒ–åè°ƒå™¨
        
        Args:
            causal_analyzer: å› æœåˆ†æå™¨å®ä¾‹
            llm_service: LLMæœåŠ¡å®ä¾‹
            input_validator: è¾“å…¥éªŒè¯å™¨å®ä¾‹
        """
        self.causal_analyzer = causal_analyzer
        self.llm_service = llm_service
        self.input_validator = input_validator
        self.parser = NaturalLanguageParser(llm_service, input_validator)
        
        # å·¥ä½œæµçŠ¶æ€
        self.current_state = WorkflowState(
            stage=WorkflowStage.INPUT_PARSING,
            progress=0.0,
            message="å‡†å¤‡å¼€å§‹åˆ†æ",
            data={},
            errors=[]
        )
        
        # å›è°ƒå‡½æ•°ï¼ˆç”¨äºUIæ›´æ–°ï¼‰
        self.progress_callback = None
    
    def set_progress_callback(self, callback):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callback = callback
    
    async def _update_progress(self, stage: WorkflowStage, progress: float, message: str, data: Dict = None):
        """æ›´æ–°å·¥ä½œæµè¿›åº¦"""
        self.current_state.stage = stage
        self.current_state.progress = progress
        self.current_state.message = message
        if data:
            self.current_state.data.update(data)
        
        logger.info(f"å·¥ä½œæµè¿›åº¦: {stage.value} - {progress:.1%} - {message}")
        
        if self.progress_callback:
            await self.progress_callback(self.current_state)
    
    async def execute_analysis(self, user_input: str, language: str = "zh") -> CausalAnalysisResult:
        """
        æ‰§è¡Œå®Œæ•´çš„å› æœæ¨æ–­åˆ†ææµç¨‹
        
        Args:
            user_input: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥
            language: è¯­è¨€ä»£ç 
            
        Returns:
            CausalAnalysisResult: åˆ†æç»“æœ
        """
        try:
            # é˜¶æ®µ1: è¾“å…¥è§£æ
            await self._update_progress(
                WorkflowStage.INPUT_PARSING, 
                0.1, 
                "æ­£åœ¨è§£æç”¨æˆ·è¾“å…¥..." if language == "zh" else "Parsing user input..."
            )
            
            parsed_params = await self.parser.parse_input(user_input, language)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…
            if parsed_params.missing_params:
                clarification = self.parser.generate_clarification_prompt(parsed_params, language)
                await self._update_progress(
                    WorkflowStage.PARAMETER_VALIDATION,
                    0.15,
                    f"éœ€è¦è¡¥å……ä¿¡æ¯: {clarification}" if language == "zh" else f"Need clarification: {clarification}",
                    {"parsed_params": parsed_params, "clarification": clarification}
                )
                # è¿”å›éƒ¨åˆ†ç»“æœï¼Œç­‰å¾…ç”¨æˆ·è¡¥å……
                return self._create_partial_result(parsed_params, clarification, language)
            
            # é˜¶æ®µ2: å‚æ•°éªŒè¯
            await self._update_progress(
                WorkflowStage.PARAMETER_VALIDATION,
                0.2,
                "éªŒè¯åˆ†æå‚æ•°..." if language == "zh" else "Validating parameters..."
            )
            
            # éªŒè¯å‚æ•°
            validation_result = await self._validate_parameters(parsed_params, language)
            if not validation_result["valid"]:
                error_msg = validation_result["message"]
                self.current_state.errors.append(error_msg)
                await self._update_progress(
                    WorkflowStage.ERROR,
                    0.2,
                    error_msg
                )
                return self._create_error_result(error_msg, language)
            
            # åˆ›å»ºåˆ†æè¯·æ±‚
            request = CausalAnalysisRequest(
                exposure_gene=parsed_params.gene,
                outcome_trait=parsed_params.disease,
                tissue_context=parsed_params.tissue or "Whole_Blood",
                analysis_type=AnalysisType.FULL_CAUSAL_ANALYSIS,
                include_pathway_analysis=True,
                include_drug_analysis=True,
                language=language,
                show_thinking=False
            )
            
            # é˜¶æ®µ3-7: LLMé©±åŠ¨çš„åˆ†ææ‰§è¡Œ
            result = await self._execute_llm_driven_analysis(request, language)
            
            # é˜¶æ®µ8: å®Œæˆ
            await self._update_progress(
                WorkflowStage.COMPLETED,
                1.0,
                "åˆ†æå®Œæˆï¼" if language == "zh" else "Analysis completed!",
                {"result": result}
            )
            
            return result
            
        except Exception as e:
            error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}" if language == "zh" else f"Error during analysis: {str(e)}"
            logger.error(error_msg, exc_info=True)
            self.current_state.errors.append(error_msg)
            await self._update_progress(WorkflowStage.ERROR, 0.0, error_msg)
            return self._create_error_result(error_msg, language)
    
    async def _validate_parameters(self, parsed_params: ParsedParameters, language: str) -> Dict[str, Any]:
        """éªŒè¯è§£æçš„å‚æ•°"""
        errors = []
        
        # éªŒè¯åŸºå› 
        if parsed_params.gene:
            gene_valid, gene_error = self.input_validator.validate_gene(parsed_params.gene, language)
            if not gene_valid:
                errors.append(f"åŸºå› éªŒè¯å¤±è´¥: {gene_error}" if language == "zh" else f"Gene validation failed: {gene_error}")
        
        # éªŒè¯ç–¾ç—…
        if parsed_params.disease:
            trait_valid, trait_message, trait_info = self.input_validator.validate_gwas_trait(parsed_params.disease, language)
            if not trait_valid:
                errors.append(f"ç–¾ç—…éªŒè¯å¤±è´¥: {trait_message}" if language == "zh" else f"Disease validation failed: {trait_message}")
        
        # éªŒè¯ç»„ç»‡
        if parsed_params.tissue:
            tissue_valid, tissue_error = self.input_validator.validate_tissue(parsed_params.tissue, language)
            if not tissue_valid:
                errors.append(f"ç»„ç»‡éªŒè¯å¤±è´¥: {tissue_error}" if language == "zh" else f"Tissue validation failed: {tissue_error}")
        
        if errors:
            return {
                "valid": False,
                "message": "; ".join(errors),
                "errors": errors
            }
        
        return {"valid": True, "message": "å‚æ•°éªŒè¯é€šè¿‡" if language == "zh" else "Parameters validated"}
    
    async def _execute_llm_driven_analysis(self, request: CausalAnalysisRequest, language: str) -> CausalAnalysisResult:
        """æ‰§è¡ŒLLMé©±åŠ¨çš„å› æœåˆ†ææµç¨‹"""

        # åˆå§‹åŒ–ç»“æœç»“æ„
        from models import CausalAnalysisResult, AnalysisStep
        import time

        start_time = time.time()
        result = CausalAnalysisResult(
            request=request,
            analysis_steps=[],
            summary={},
            interpretation="",
            recommendations=[],
            total_execution_time=0.0,
            success=False,
            warnings=[]
        )

        # è®°å½•åˆ†ææ­¥éª¤
        from models import AnalysisStep

        try:
            # é˜¶æ®µ3: LLMé©±åŠ¨çš„eQTLåˆ†æ
            await self._update_progress(
                WorkflowStage.EQTL_ANALYSIS,
                0.3,
                f"ğŸ¤– LLMæ­£åœ¨åˆ†æ{request.exposure_gene}åŸºå› çš„eQTLç­–ç•¥..." if language == "zh" else f"ğŸ¤– LLM analyzing eQTL strategy for {request.exposure_gene}..."
            )

            eqtl_step_start = time.time()
            eqtl_result = await self._llm_guided_eqtl_analysis(request, language)
            result.eqtl_instruments = eqtl_result.get("instruments", [])

            # è®°å½•eQTLæ­¥éª¤
            result.analysis_steps.append(AnalysisStep(
                step_name="eQTL Analysis",
                status="completed",
                server_used="eQTL Server",
                execution_time=time.time() - eqtl_step_start,
                error_message=None
            ))

            # LLMè¯„ä¼°eQTLè´¨é‡å¹¶å†³å®šä¸‹ä¸€æ­¥
            eqtl_assessment = await self._llm_assess_eqtl_quality(eqtl_result, language)

            if not eqtl_assessment["proceed"]:
                # LLMå»ºè®®åœæ­¢åˆ†æ
                result.interpretation = eqtl_assessment["reason"]
                result.recommendations = eqtl_assessment["recommendations"]
                return result

            # é˜¶æ®µ4: LLMé©±åŠ¨çš„GWASåˆ†æ
            await self._update_progress(
                WorkflowStage.GWAS_ANALYSIS,
                0.5,
                f"ğŸ¤– LLMæ­£åœ¨ä¼˜åŒ–{request.outcome_trait}çš„GWASæŸ¥è¯¢..." if language == "zh" else f"ğŸ¤– LLM optimizing GWAS query for {request.outcome_trait}..."
            )

            gwas_step_start = time.time()
            gwas_result = await self._llm_guided_gwas_analysis(request, eqtl_result, language)
            result.harmonized_data = gwas_result.get("harmonized_data", [])

            # è®°å½•GWASæ­¥éª¤
            result.analysis_steps.append(AnalysisStep(
                step_name="GWAS Analysis",
                status="completed",
                server_used="GWAS Server",
                execution_time=time.time() - gwas_step_start,
                error_message=None
            ))

            # LLMè¯„ä¼°æ•°æ®è´¨é‡
            data_assessment = await self._llm_assess_data_quality(eqtl_result, gwas_result, language)

            # é˜¶æ®µ5: LLMé©±åŠ¨çš„MRåˆ†æ
            await self._update_progress(
                WorkflowStage.MR_ANALYSIS,
                0.7,
                f"ğŸ¤– LLMæ­£åœ¨é€‰æ‹©æœ€ä½³MRæ–¹æ³•..." if language == "zh" else f"ğŸ¤– LLM selecting optimal MR methods..."
            )

            mr_step_start = time.time()
            mr_result = await self._llm_guided_mr_analysis(request, result.harmonized_data, data_assessment, language)
            result.mr_results = mr_result

            # è®°å½•MRæ­¥éª¤
            result.analysis_steps.append(AnalysisStep(
                step_name="Mendelian Randomization",
                status="completed",
                server_used="MR Server",
                execution_time=time.time() - mr_step_start,
                error_message=None
            ))

            # é˜¶æ®µ6: LLMé©±åŠ¨çš„çŸ¥è¯†æ•´åˆ
            await self._update_progress(
                WorkflowStage.KNOWLEDGE_INTEGRATION,
                0.85,
                f"ğŸ¤– LLMæ­£åœ¨æ•´åˆç”Ÿç‰©å­¦çŸ¥è¯†..." if language == "zh" else f"ğŸ¤– LLM integrating biological knowledge..."
            )

            knowledge_step_start = time.time()
            knowledge_result = await self._llm_guided_knowledge_integration(request, mr_result, language)
            result.gene_annotation = knowledge_result.get("gene_annotation")
            result.drug_analysis = knowledge_result.get("drug_analysis")

            # è®°å½•çŸ¥è¯†æ•´åˆæ­¥éª¤
            result.analysis_steps.append(AnalysisStep(
                step_name="Knowledge Integration",
                status="completed",
                server_used="Knowledge Server",
                execution_time=time.time() - knowledge_step_start,
                error_message=None
            ))

            # é˜¶æ®µ7: LLMé©±åŠ¨çš„ç»“æœè§£é‡Š
            await self._update_progress(
                WorkflowStage.RESULT_INTERPRETATION,
                0.95,
                f"ğŸ¤– LLMæ­£åœ¨ç”Ÿæˆæ™ºèƒ½è§£é‡Š..." if language == "zh" else f"ğŸ¤– LLM generating intelligent interpretation..."
            )

            interpretation_result = await self._llm_generate_comprehensive_interpretation(result, language)
            result.interpretation = interpretation_result["interpretation"]
            result.recommendations = interpretation_result["recommendations"]

            # ç”Ÿæˆå®Œæ•´çš„summaryä¿¡æ¯
            result.summary = self._generate_summary(result)

            # ä¿ç•™MRç»“è®º
            if result.mr_results and isinstance(result.mr_results, dict):
                mr_conclusion = result.mr_results.get('summary', {}).get('conclusion', '')
                if mr_conclusion:
                    result.summary["causal_conclusion"] = mr_conclusion

            # æ·»åŠ LLMç”Ÿæˆçš„å…¶ä»–æ‘˜è¦ä¿¡æ¯
            llm_summary = interpretation_result.get("summary", {})
            for key, value in llm_summary.items():
                if key not in result.summary:  # ä¸è¦†ç›–å·²æœ‰çš„å…³é”®ä¿¡æ¯
                    result.summary[key] = value

            result.success = True

        except Exception as e:
            logger.error(f"LLMå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            result.interpretation = f"åˆ†æå¤±è´¥: {str(e)}" if language == "zh" else f"Analysis failed: {str(e)}"
            result.success = False

        finally:
            result.total_execution_time = time.time() - start_time

        return result

    def _generate_summary(self, result: 'CausalAnalysisResult') -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        summary = {
            "exposure_gene": result.request.exposure_gene,
            "outcome_trait": result.request.outcome_trait,
            "tissue_context": result.request.tissue_context,
            "n_instruments": len(result.eqtl_instruments) if result.eqtl_instruments else 0,
            "n_harmonized_snps": len(result.harmonized_data) if result.harmonized_data else 0,
            "analysis_completed": result.success
        }

        if result.mr_results:
            mr_summary = result.mr_results.get("summary", {})
            summary.update({
                "causal_conclusion": mr_summary.get("conclusion", "No conclusion available"),
                "primary_method": "Inverse Variance Weighted"
            })

        return summary

    async def _generate_fallback_interpretation(self, result: 'CausalAnalysisResult', language: str) -> str:
        """ç”Ÿæˆå¤‡ç”¨è¯¦ç»†è§£é‡Šï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰"""
        # ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼çš„è§£é‡Šç”Ÿæˆé€»è¾‘
        return await self.causal_analyzer._generate_interpretation(result, language, show_thinking=False)

    async def _generate_fallback_recommendations(self, result: 'CausalAnalysisResult', language: str) -> List[str]:
        """ç”Ÿæˆå¤‡ç”¨æ¨èå»ºè®®ï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰"""
        # ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼çš„å»ºè®®ç”Ÿæˆé€»è¾‘
        return await self.causal_analyzer._generate_recommendations(result, language, show_thinking=False)
    
    def _create_partial_result(self, parsed_params: ParsedParameters, clarification: str, language: str) -> CausalAnalysisResult:
        """åˆ›å»ºéƒ¨åˆ†ç»“æœï¼ˆéœ€è¦ç”¨æˆ·æ¾„æ¸…ï¼‰"""
        from models import AnalysisStep
        
        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„è¯·æ±‚å¯¹è±¡
        request = CausalAnalysisRequest(
            exposure_gene=parsed_params.gene or "UNKNOWN",
            outcome_trait=parsed_params.disease or "UNKNOWN",
            tissue_context=parsed_params.tissue or "Whole_Blood",
            language=language
        )
        
        step = AnalysisStep(
            step_name="Parameter Clarification",
            status="pending",
            input_data={"parsed_params": parsed_params.__dict__},
            output_data={"clarification": clarification}
        )
        
        return CausalAnalysisResult(
            request=request,
            analysis_steps=[step],
            summary={"status": "éœ€è¦æ¾„æ¸…å‚æ•°" if language == "zh" else "Parameter clarification needed"},
            interpretation=clarification,
            recommendations=[],
            total_execution_time=0.0,
            success=False,
            warnings=[clarification]
        )
    
    def _create_error_result(self, error_message: str, language: str) -> CausalAnalysisResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        from models import AnalysisStep
        
        request = CausalAnalysisRequest(
            exposure_gene="ERROR",
            outcome_trait="ERROR",
            tissue_context="Whole_Blood",
            language=language
        )
        
        step = AnalysisStep(
            step_name="Error",
            status="failed",
            error_message=error_message
        )
        
        return CausalAnalysisResult(
            request=request,
            analysis_steps=[step],
            summary={"status": "åˆ†æå¤±è´¥" if language == "zh" else "Analysis failed"},
            interpretation=error_message,
            recommendations=[],
            total_execution_time=0.0,
            success=False,
            error_message=error_message
        )

    async def _llm_guided_eqtl_analysis(self, request: CausalAnalysisRequest, language: str) -> Dict[str, Any]:
        """LLMæŒ‡å¯¼çš„eQTLåˆ†æ"""

        # LLMå†³ç­–ï¼šé€‰æ‹©æœ€ä½³ç»„ç»‡å’Œåˆ†æç­–ç•¥
        strategy_prompt = self._create_eqtl_strategy_prompt(request, language)

        if self.llm_service.is_available:
            try:
                strategy_response = await self.llm_service._generate_text(strategy_prompt, max_length=512)
                strategy = self._parse_llm_strategy(strategy_response)
                logger.info(f"ğŸ¤– LLM eQTLç­–ç•¥: {strategy}")
            except Exception as e:
                logger.warning(f"LLMç­–ç•¥ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥: {e}")
                strategy = {"tissue": request.tissue_context, "approach": "standard"}
        else:
            strategy = {"tissue": request.tissue_context, "approach": "standard"}

        # æ‰§è¡ŒeQTLåˆ†æ
        eqtl_result = await self.causal_analyzer.mcp_client.call_eqtl_server(
            request.exposure_gene,
            strategy.get("tissue", request.tissue_context)
        )

        # æ·»åŠ LLMç­–ç•¥ä¿¡æ¯
        eqtl_result["llm_strategy"] = strategy
        return eqtl_result

    async def _llm_assess_eqtl_quality(self, eqtl_result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """LLMè¯„ä¼°eQTLæ•°æ®è´¨é‡"""

        instruments = eqtl_result.get("instruments", [])

        if not self.llm_service.is_available:
            # ç®€å•è§„åˆ™è¯„ä¼°
            return {
                "proceed": len(instruments) > 0,
                "reason": f"æ‰¾åˆ° {len(instruments)} ä¸ªå·¥å…·å˜é‡" if language == "zh" else f"Found {len(instruments)} instruments",
                "recommendations": []
            }

        # LLMè¯„ä¼°
        assessment_prompt = self._create_eqtl_assessment_prompt(eqtl_result, language)

        try:
            assessment_response = await self.llm_service._generate_text(assessment_prompt, max_length=512)
            assessment = self._parse_llm_assessment(assessment_response)
            return assessment
        except Exception as e:
            logger.warning(f"LLMè¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„ä¼°: {e}")
            return {
                "proceed": len(instruments) > 0,
                "reason": f"æ‰¾åˆ° {len(instruments)} ä¸ªå·¥å…·å˜é‡" if language == "zh" else f"Found {len(instruments)} instruments",
                "recommendations": []
            }

    async def _llm_guided_gwas_analysis(self, request: CausalAnalysisRequest, eqtl_result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """LLMæŒ‡å¯¼çš„GWASåˆ†æ"""

        # LLMä¼˜åŒ–ç–¾ç—…æŸ¥è¯¢
        if self.llm_service.is_available:
            try:
                query_prompt = self._create_gwas_query_prompt(request, eqtl_result, language)
                query_response = await self.llm_service._generate_text(query_prompt, max_length=256)
                optimized_query = self._parse_llm_query(query_response, request.outcome_trait)
            except Exception as e:
                logger.warning(f"LLMæŸ¥è¯¢ä¼˜åŒ–å¤±è´¥: {e}")
                optimized_query = request.outcome_trait
        else:
            optimized_query = request.outcome_trait

        # ä½¿ç”¨ç–¾ç—…æ˜ å°„å™¨è·å–ç ”ç©¶ID
        outcome_id = self.causal_analyzer.disease_mapper.get_study_id_for_disease(optimized_query)
        if not outcome_id:
            outcome_id = self.causal_analyzer.disease_mapper.get_study_id_for_disease(request.outcome_trait)

        if not outcome_id:
            raise ValueError(f"æ— æ³•æ‰¾åˆ°ç–¾ç—… '{request.outcome_trait}' å¯¹åº”çš„GWASç ”ç©¶")

        # æ‰§è¡ŒGWASåˆ†æ
        gwas_result = await self.causal_analyzer.mcp_client.call_gwas_server(
            eqtl_result.get("instruments", []),
            outcome_id
        )

        gwas_result["llm_optimized_query"] = optimized_query
        return gwas_result

    async def _llm_assess_data_quality(self, eqtl_result: Dict[str, Any], gwas_result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """LLMè¯„ä¼°æ•°æ®è´¨é‡å¹¶æ¨èåˆ†æç­–ç•¥"""

        if not self.llm_service.is_available:
            # ç®€å•è§„åˆ™è¯„ä¼°
            harmonized_count = len(gwas_result.get("harmonized_data", []))
            return {
                "quality_score": min(harmonized_count / 10, 1.0),
                "recommended_methods": ["IVW", "Weighted Median"],
                "confidence_level": "medium"
            }

        # LLMè¯„ä¼°æ•°æ®è´¨é‡
        quality_prompt = self._create_data_quality_prompt(eqtl_result, gwas_result, language)

        try:
            quality_response = await self.llm_service._generate_text(quality_prompt, max_length=512)
            quality_assessment = self._parse_llm_quality_assessment(quality_response)
            return quality_assessment
        except Exception as e:
            logger.warning(f"LLMæ•°æ®è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            harmonized_count = len(gwas_result.get("harmonized_data", []))
            return {
                "quality_score": min(harmonized_count / 10, 1.0),
                "recommended_methods": ["IVW", "Weighted Median"],
                "confidence_level": "medium"
            }

    async def _llm_guided_mr_analysis(self, request: CausalAnalysisRequest, harmonized_data: List[Dict], data_assessment: Dict[str, Any], language: str) -> Dict[str, Any]:
        """LLMæŒ‡å¯¼çš„MRåˆ†æ"""

        # LLMé€‰æ‹©æœ€ä½³MRæ–¹æ³•
        if self.llm_service.is_available:
            try:
                method_prompt = self._create_mr_method_prompt(harmonized_data, data_assessment, language)
                method_response = await self.llm_service._generate_text(method_prompt, max_length=256)
                selected_methods = self._parse_llm_methods(method_response)
                logger.info(f"ğŸ¤– LLMæ¨èçš„MRæ–¹æ³•: {selected_methods}")
            except Exception as e:
                logger.warning(f"LLMæ–¹æ³•é€‰æ‹©å¤±è´¥: {e}")
                selected_methods = data_assessment.get("recommended_methods", ["IVW", "Weighted Median"])
        else:
            selected_methods = data_assessment.get("recommended_methods", ["IVW", "Weighted Median"])

        # æ‰§è¡ŒMRåˆ†æ
        mr_result = await self.causal_analyzer.mcp_client.call_mr_server(
            harmonized_data,
            f"{request.exposure_gene} Expression",
            request.outcome_trait,
            language
        )

        mr_result["llm_selected_methods"] = selected_methods
        mr_result["data_quality_assessment"] = data_assessment
        return mr_result

    def _create_data_quality_prompt(self, eqtl_result: Dict[str, Any], gwas_result: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºæ•°æ®è´¨é‡è¯„ä¼°çš„LLMæç¤º"""

        eqtl_count = len(eqtl_result.get("instruments", []))
        harmonized_count = len(gwas_result.get("harmonized_data", []))

        if language == "zh":
            prompt = f"""
ä½œä¸ºç”Ÿç‰©ç»Ÿè®¡å­¦ä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å­Ÿå¾·å°”éšæœºåŒ–åˆ†æçš„æ•°æ®è´¨é‡ï¼š

eQTLæ•°æ®ï¼š
- å·¥å…·å˜é‡æ•°é‡ï¼š{eqtl_count}
- æ•°æ®æ¥æºï¼š{eqtl_result.get('data_source', 'Unknown')}

GWASæ•°æ®ï¼š
- åè°ƒåSNPæ•°é‡ï¼š{harmonized_count}
- æ•°æ®æ¥æºï¼š{gwas_result.get('data_source', 'Unknown')}

è¯·è¯„ä¼°ï¼š
1. æ•°æ®è´¨é‡ç­‰çº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
2. æ¨èçš„MRæ–¹æ³•ï¼ˆä»IVWã€MR-Eggerã€Weighted Medianä¸­é€‰æ‹©ï¼‰
3. ç½®ä¿¡åº¦æ°´å¹³ï¼ˆé«˜/ä¸­/ä½ï¼‰
4. æ½œåœ¨çš„åˆ†æé™åˆ¶

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "quality_level": "é«˜/ä¸­/ä½",
    "recommended_methods": ["æ–¹æ³•1", "æ–¹æ³•2"],
    "confidence_level": "é«˜/ä¸­/ä½",
    "limitations": "åˆ†æé™åˆ¶è¯´æ˜"
}}
"""
        else:
            prompt = f"""
As a biostatistics expert, please assess the data quality for the following Mendelian Randomization analysis:

eQTL Data:
- Number of instruments: {eqtl_count}
- Data source: {eqtl_result.get('data_source', 'Unknown')}

GWAS Data:
- Number of harmonized SNPs: {harmonized_count}
- Data source: {gwas_result.get('data_source', 'Unknown')}

Please assess:
1. Data quality level (High/Medium/Low)
2. Recommended MR methods (choose from IVW, MR-Egger, Weighted Median)
3. Confidence level (High/Medium/Low)
4. Potential analysis limitations

Please respond in JSON format:
{{
    "quality_level": "High/Medium/Low",
    "recommended_methods": ["method1", "method2"],
    "confidence_level": "High/Medium/Low",
    "limitations": "Analysis limitations description"
}}
"""

        return prompt

    async def _llm_guided_knowledge_integration(self, request: CausalAnalysisRequest, mr_result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """LLMæŒ‡å¯¼çš„çŸ¥è¯†æ•´åˆ"""

        knowledge_result = {}

        # åŸºå› æ³¨é‡Š
        if request.include_pathway_analysis:
            gene_annotation = await self.causal_analyzer.mcp_client.call_knowledge_server(
                request.exposure_gene,
                "gene_annotation"
            )
            knowledge_result["gene_annotation"] = gene_annotation

        # è¯ç‰©åˆ†æ
        if request.include_drug_analysis:
            drug_analysis = await self.causal_analyzer.mcp_client.call_knowledge_server_drug(
                request.exposure_gene
            )
            knowledge_result["drug_analysis"] = drug_analysis

        # LLMæ•´åˆçŸ¥è¯†
        if self.llm_service.is_available:
            try:
                integration_prompt = self._create_knowledge_integration_prompt(request, mr_result, knowledge_result, language)
                integration_response = await self.llm_service._generate_text(integration_prompt, max_length=1024)
                integrated_knowledge = self._parse_llm_integration(integration_response)
                knowledge_result["llm_integration"] = integrated_knowledge
            except Exception as e:
                logger.warning(f"LLMçŸ¥è¯†æ•´åˆå¤±è´¥: {e}")

        return knowledge_result

    async def _llm_generate_comprehensive_interpretation(self, result: 'CausalAnalysisResult', language: str) -> Dict[str, Any]:
        """LLMç”Ÿæˆç»¼åˆè§£é‡Š"""

        if not self.llm_service.is_available:
            # ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼çš„è¯¦ç»†è§£é‡Šç”Ÿæˆé€»è¾‘
            detailed_interpretation = await self._generate_fallback_interpretation(result, language)
            fallback_recommendations = await self._generate_fallback_recommendations(result, language)

            mr_conclusion = "æ— MRç»“æœ"
            if result.mr_results and isinstance(result.mr_results, dict):
                mr_conclusion = result.mr_results.get('summary', {}).get('conclusion', 'æ— ç»“è®º')

            return {
                "interpretation": detailed_interpretation,
                "recommendations": fallback_recommendations,
                "summary": {
                    "status": "completed",
                    "causal_conclusion": mr_conclusion
                }
            }

        # LLMç”Ÿæˆç»¼åˆè§£é‡Š
        try:
            interpretation_prompt = self._create_comprehensive_interpretation_prompt(result, language)
            interpretation_response = await self.llm_service._generate_text(interpretation_prompt, max_length=2048)

            # æ£€æŸ¥LLMæ˜¯å¦è¿”å›äº†æœ‰æ•ˆå“åº”
            if interpretation_response and interpretation_response.strip():
                interpretation_result = self._parse_llm_interpretation(interpretation_response)
                # éªŒè¯è§£æç»“æœæ˜¯å¦åŒ…å«å¿…è¦çš„å­—æ®µ
                if interpretation_result.get("interpretation") and interpretation_result.get("recommendations"):
                    return interpretation_result
                else:
                    logger.warning("LLMè§£é‡Šè§£æç»“æœä¸å®Œæ•´ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            else:
                logger.warning("LLMè¿”å›ç©ºå“åº”ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")

        except Exception as e:
            logger.warning(f"LLMè§£é‡Šç”Ÿæˆå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")

        # LLMå¤±è´¥æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨çš„è¯¦ç»†è§£é‡Šç”Ÿæˆ
        logger.info("ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼çš„è¯¦ç»†è§£é‡Šç”Ÿæˆé€»è¾‘")
        detailed_interpretation = await self._generate_fallback_interpretation(result, language)
        fallback_recommendations = await self._generate_fallback_recommendations(result, language)

        mr_conclusion = "æ— MRç»“æœ"
        if result.mr_results and isinstance(result.mr_results, dict):
            mr_conclusion = result.mr_results.get('summary', {}).get('conclusion', 'æ— ç»“è®º')

        return {
            "interpretation": detailed_interpretation,
            "recommendations": fallback_recommendations,
            "summary": {
                "status": "completed",
                "causal_conclusion": mr_conclusion
            }
        }

    # ========== LLMæç¤ºè¯åˆ›å»ºæ–¹æ³• ==========

    def _create_eqtl_strategy_prompt(self, request: CausalAnalysisRequest, language: str) -> str:
        """åˆ›å»ºeQTLç­–ç•¥æç¤ºè¯"""
        if language == "zh":
            return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŸºå› è¡¨è¾¾æ•°é‡æ€§çŠ¶ä½ç‚¹(eQTL)åˆ†æä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ç ”ç©¶è®¾è®¡æœ€ä½³çš„eQTLåˆ†æç­–ç•¥ï¼š

ç ”ç©¶ç›®æ ‡ï¼šåˆ†æ{request.exposure_gene}åŸºå› å¯¹{request.outcome_trait}çš„å› æœæ•ˆåº”
å½“å‰ç»„ç»‡ï¼š{request.tissue_context}

è¯·è€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
1. è¯¥åŸºå› åœ¨ä¸åŒç»„ç»‡ä¸­çš„è¡¨è¾¾æ¨¡å¼
2. ç–¾ç—…çš„ç”Ÿç‰©å­¦ç›¸å…³æ€§
3. eQTLæ•ˆåº”é‡çš„ç»„ç»‡ç‰¹å¼‚æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›ç­–ç•¥ï¼š
{{
    "tissue": "æ¨èçš„æœ€ä½³ç»„ç»‡",
    "approach": "åˆ†ææ–¹æ³•(standard/multi-tissue/tissue-specific)",
    "reasoning": "é€‰æ‹©ç†ç”±"
}}
"""
        else:
            return f"""
You are a professional eQTL analysis expert. Please design the optimal eQTL analysis strategy for:

Research goal: Analyze causal effect of {request.exposure_gene} gene on {request.outcome_trait}
Current tissue: {request.tissue_context}

Consider:
1. Gene expression patterns across tissues
2. Disease biological relevance
3. Tissue-specific eQTL effect sizes

Return strategy in JSON format:
{{
    "tissue": "recommended optimal tissue",
    "approach": "analysis method (standard/multi-tissue/tissue-specific)",
    "reasoning": "selection rationale"
}}
"""

    def _create_eqtl_assessment_prompt(self, eqtl_result: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºeQTLè´¨é‡è¯„ä¼°æç¤ºè¯"""
        instruments = eqtl_result.get("instruments", [])
        instrument_count = len(instruments)

        if language == "zh":
            return f"""
ä½œä¸ºeQTLæ•°æ®è´¨é‡ä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹eQTLåˆ†æç»“æœï¼š

å·¥å…·å˜é‡æ•°é‡ï¼š{instrument_count}ä¸ª
æ•°æ®æ¥æºï¼šGTExæ•°æ®åº“

è¯„ä¼°æ ‡å‡†ï¼š
1. å·¥å…·å˜é‡æ•°é‡æ˜¯å¦å……è¶³ï¼ˆé€šå¸¸éœ€è¦â‰¥3ä¸ªï¼‰
2. æ•ˆåº”é‡æ˜¯å¦åˆç†
3. æ˜¯å¦é€‚åˆè¿›è¡Œå­Ÿå¾·å°”éšæœºåŒ–åˆ†æ

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ï¼š
{{
    "proceed": true/false,
    "reason": "è¯„ä¼°ç†ç”±",
    "recommendations": ["å»ºè®®åˆ—è¡¨"]
}}
"""
        else:
            return f"""
As an eQTL data quality expert, please assess the following eQTL analysis results:

Number of instruments: {instrument_count}
Data source: GTEx database

Assessment criteria:
1. Sufficient number of instruments (usually â‰¥3)
2. Reasonable effect sizes
3. Suitability for Mendelian randomization

Return assessment in JSON format:
{{
    "proceed": true/false,
    "reason": "assessment rationale",
    "recommendations": ["recommendation list"]
}}
"""

    def _create_gwas_query_prompt(self, request: CausalAnalysisRequest, eqtl_result: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºGWASæŸ¥è¯¢ä¼˜åŒ–æç¤ºè¯"""
        if language == "zh":
            return f"""
ä½œä¸ºGWASæ•°æ®ä¸“å®¶ï¼Œè¯·ä¼˜åŒ–ä»¥ä¸‹ç–¾ç—…çš„æŸ¥è¯¢ç­–ç•¥ï¼š

ç›®æ ‡ç–¾ç—…ï¼š{request.outcome_trait}
åŸºå› ï¼š{request.exposure_gene}
eQTLå·¥å…·å˜é‡æ•°é‡ï¼š{len(eqtl_result.get("instruments", []))}

è¯·è€ƒè™‘ï¼š
1. ç–¾ç—…çš„æ ‡å‡†æœ¯è¯­å’ŒåŒä¹‰è¯
2. ç›¸å…³çš„è¡¨å‹å’Œäºšå‹
3. æ•°æ®åº“ä¸­å¯èƒ½çš„å‘½åæ–¹å¼

è¯·è¿”å›ä¼˜åŒ–åçš„æŸ¥è¯¢è¯ï¼ˆå•ä¸ªæœ€ä½³æœ¯è¯­ï¼‰ï¼š
"""
        else:
            return f"""
As a GWAS data expert, please optimize the query strategy for:

Target disease: {request.outcome_trait}
Gene: {request.exposure_gene}
Number of eQTL instruments: {len(eqtl_result.get("instruments", []))}

Consider:
1. Standard terminology and synonyms
2. Related phenotypes and subtypes
3. Possible naming conventions in databases

Return optimized query term (single best term):
"""

    # ========== LLMå“åº”è§£ææ–¹æ³• ==========

    def _parse_llm_strategy(self, response: str) -> Dict[str, Any]:
        """è§£æLLMç­–ç•¥å“åº”"""
        import json
        import re

        try:
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                strategy = json.loads(json_match.group())
                return strategy
        except:
            pass

        # å¤‡ç”¨è§£æ
        return {
            "tissue": "Whole_Blood",
            "approach": "standard",
            "reasoning": "Default strategy due to parsing failure"
        }

    def _parse_llm_assessment(self, response: str) -> Dict[str, Any]:
        """è§£æLLMè¯„ä¼°å“åº”"""
        import json
        import re

        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                assessment = json.loads(json_match.group())
                return assessment
        except:
            pass

        # å¤‡ç”¨è§£æ
        proceed = "proceed" in response.lower() or "ç»§ç»­" in response
        return {
            "proceed": proceed,
            "reason": "Parsed from text response",
            "recommendations": []
        }

    def _parse_llm_query(self, response: str, original_query: str) -> str:
        """è§£æLLMæŸ¥è¯¢ä¼˜åŒ–å“åº”"""
        # ç®€å•æå–ï¼šå–ç¬¬ä¸€è¡Œéç©ºæ–‡æœ¬
        lines = [line.strip() for line in response.split('\n') if line.strip()]
        if lines:
            optimized = lines[0]
            # ç§»é™¤å¯èƒ½çš„å¼•å·
            optimized = optimized.strip('"\'')
            return optimized if optimized else original_query
        return original_query

    def _parse_llm_quality_assessment(self, response: str) -> Dict[str, Any]:
        """è§£æLLMæ•°æ®è´¨é‡è¯„ä¼°å“åº”"""
        import json
        import re

        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                assessment = json.loads(json_match.group())
                return assessment
        except:
            pass

        # å¤‡ç”¨è§£æ
        return {
            "quality_score": 0.7,
            "recommended_methods": ["IVW", "Weighted Median"],
            "confidence_level": "medium"
        }

    def _create_mr_method_prompt(self, harmonized_data: List[Dict], data_assessment: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºMRæ–¹æ³•é€‰æ‹©çš„LLMæç¤º"""

        snp_count = len(harmonized_data)
        quality_level = data_assessment.get("quality_level", "medium")

        if language == "zh":
            prompt = f"""
ä½œä¸ºå­Ÿå¾·å°”éšæœºåŒ–åˆ†æä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹æ•°æ®é€‰æ‹©æœ€é€‚åˆçš„MRæ–¹æ³•ï¼š

æ•°æ®æ¦‚å†µï¼š
- SNPæ•°é‡ï¼š{snp_count}
- æ•°æ®è´¨é‡ï¼š{quality_level}
- å½“å‰è¯„ä¼°ï¼š{data_assessment.get('limitations', 'æ— ç‰¹æ®Šé™åˆ¶')}

å¯é€‰æ–¹æ³•ï¼š
1. IVW (Inverse Variance Weighted) - æ ‡å‡†æ–¹æ³•ï¼Œå‡è®¾æ— å¤šæ•ˆæ€§
2. MR-Egger - æ£€æµ‹å’Œæ ¡æ­£å¤šæ•ˆæ€§åå€š
3. Weighted Median - å¯¹å¼‚å¸¸å€¼ç¨³å¥
4. Weighted Mode - å¯¹å¤šæ•ˆæ€§ç¨³å¥
5. Simple Mode - ç®€å•æ¨¡å¼ä¼°è®¡

è¯·æ ¹æ®æ•°æ®ç‰¹ç‚¹é€‰æ‹©2-3ä¸ªæœ€é€‚åˆçš„æ–¹æ³•ï¼Œç”¨é€—å·åˆ†éš”ï¼š
"""
        else:
            prompt = f"""
As a Mendelian Randomization analysis expert, please select the most appropriate MR methods for the following data:

Data Overview:
- Number of SNPs: {snp_count}
- Data quality: {quality_level}
- Current assessment: {data_assessment.get('limitations', 'No specific limitations')}

Available methods:
1. IVW (Inverse Variance Weighted) - Standard method, assumes no pleiotropy
2. MR-Egger - Detects and corrects for pleiotropic bias
3. Weighted Median - Robust to outliers
4. Weighted Mode - Robust to pleiotropy
5. Simple Mode - Simple mode estimation

Please select 2-3 most suitable methods based on data characteristics, separated by commas:
"""

        return prompt

    def _create_eqtl_strategy_prompt(self, request: CausalAnalysisRequest, language: str) -> str:
        """åˆ›å»ºeQTLç­–ç•¥é€‰æ‹©çš„LLMæç¤º"""

        if language == "zh":
            prompt = f"""
ä½œä¸ºåŸºå› è¡¨è¾¾åˆ†æä¸“å®¶ï¼Œè¯·ä¸ºåŸºå›  {request.exposure_gene} åˆ¶å®šæœ€ä½³çš„eQTLåˆ†æç­–ç•¥ï¼š

åˆ†æç›®æ ‡ï¼š
- åŸºå› ï¼š{request.exposure_gene}
- ç›®æ ‡ç–¾ç—…ï¼š{request.outcome_trait}
- æŒ‡å®šç»„ç»‡ï¼š{request.tissue_context}

è¯·è€ƒè™‘ï¼š
1. è¯¥åŸºå› åœ¨ä¸åŒç»„ç»‡ä¸­çš„è¡¨è¾¾æ¨¡å¼
2. ä¸ç›®æ ‡ç–¾ç—…æœ€ç›¸å…³çš„ç»„ç»‡ç±»å‹
3. æ•°æ®å¯ç”¨æ€§å’Œè´¨é‡

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "tissue": "æ¨èçš„ç»„ç»‡ç±»å‹",
    "approach": "åˆ†ææ–¹æ³•",
    "rationale": "é€‰æ‹©ç†ç”±"
}}
"""
        else:
            prompt = f"""
As a gene expression analysis expert, please develop the optimal eQTL analysis strategy for gene {request.exposure_gene}:

Analysis Target:
- Gene: {request.exposure_gene}
- Target disease: {request.outcome_trait}
- Specified tissue: {request.tissue_context}

Please consider:
1. Expression patterns of this gene in different tissues
2. Most relevant tissue types for the target disease
3. Data availability and quality

Please respond in JSON format:
{{
    "tissue": "recommended tissue type",
    "approach": "analysis method",
    "rationale": "selection rationale"
}}
"""

        return prompt

    def _parse_llm_strategy(self, response: str) -> Dict[str, Any]:
        """è§£æLLMç­–ç•¥å“åº”"""
        import json
        import re

        try:
            # å°è¯•è§£æJSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                strategy_data = json.loads(json_match.group())
                return strategy_data
        except:
            pass

        # å¤‡ç”¨è§£æ
        return {
            "tissue": "Whole_Blood",
            "approach": "standard",
            "rationale": "Default strategy"
        }

    def _create_eqtl_assessment_prompt(self, eqtl_result: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºeQTLè´¨é‡è¯„ä¼°çš„LLMæç¤º"""

        instruments_count = len(eqtl_result.get("instruments", []))

        if language == "zh":
            prompt = f"""
ä½œä¸ºeQTLåˆ†æä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹eQTLåˆ†æç»“æœçš„è´¨é‡ï¼š

ç»“æœæ¦‚å†µï¼š
- æ‰¾åˆ°çš„å·¥å…·å˜é‡æ•°é‡ï¼š{instruments_count}
- æ•°æ®æ¥æºï¼š{eqtl_result.get('data_source', 'Unknown')}

è¯·è¯„ä¼°ï¼š
1. æ˜¯å¦åº”è¯¥ç»§ç»­è¿›è¡ŒMRåˆ†æ
2. æ•°æ®è´¨é‡è¯„çº§
3. æ½œåœ¨é—®é¢˜å’Œå»ºè®®

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "proceed": true/false,
    "quality": "é«˜/ä¸­/ä½",
    "reason": "è¯„ä¼°ç†ç”±",
    "recommendations": ["å»ºè®®1", "å»ºè®®2"]
}}
"""
        else:
            prompt = f"""
As an eQTL analysis expert, please assess the quality of the following eQTL analysis results:

Results Overview:
- Number of instruments found: {instruments_count}
- Data source: {eqtl_result.get('data_source', 'Unknown')}

Please assess:
1. Whether to proceed with MR analysis
2. Data quality rating
3. Potential issues and recommendations

Please respond in JSON format:
{{
    "proceed": true/false,
    "quality": "High/Medium/Low",
    "reason": "assessment rationale",
    "recommendations": ["recommendation1", "recommendation2"]
}}
"""

        return prompt

    def _parse_llm_assessment(self, response: str) -> Dict[str, Any]:
        """è§£æLLMè¯„ä¼°å“åº”"""
        import json
        import re

        try:
            # å°è¯•è§£æJSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                assessment_data = json.loads(json_match.group())
                return assessment_data
        except:
            pass

        # å¤‡ç”¨è§£æ
        return {
            "proceed": True,
            "quality": "medium",
            "reason": "Default assessment",
            "recommendations": []
        }

    def _create_gwas_query_prompt(self, request: CausalAnalysisRequest, eqtl_result: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºGWASæŸ¥è¯¢ä¼˜åŒ–çš„LLMæç¤º"""

        if language == "zh":
            prompt = f"""
ä½œä¸ºGWASæ•°æ®åº“ä¸“å®¶ï¼Œè¯·å°†ä»¥ä¸‹ç–¾ç—…åç§°æ ‡å‡†åŒ–ä¸ºGWASæ•°æ®åº“ä¸­å¸¸ç”¨çš„æœ¯è¯­ï¼š

åŸå§‹ç–¾ç—…åç§°ï¼š{request.outcome_trait}

é‡è¦è§„åˆ™ï¼š
1. åªè¿”å›æ ‡å‡†çš„ç–¾ç—…åç§°ï¼Œä¸è¦æ·»åŠ åŸºå› ä¿¡æ¯æˆ–å…¶ä»–ä¿®é¥°è¯
2. ä½¿ç”¨GWASæ•°æ®åº“ä¸­å¸¸è§çš„ç–¾ç—…æœ¯è¯­
3. ä¿æŒç®€æ´ï¼Œé¿å…å¤åˆæŸ¥è¯¢
4. å¸¸è§æ ‡å‡†åŒ–ç¤ºä¾‹ï¼š
   - "å† å¿ƒç—…" â†’ "coronary heart disease"
   - "å¿ƒè„ç—…" â†’ "coronary heart disease"
   - "ç³–å°¿ç—…" â†’ "type 2 diabetes"
   - "é˜¿å°”èŒ¨æµ·é»˜ç—…" â†’ "alzheimer disease"

è¯·åªè¿”å›æ ‡å‡†åŒ–çš„ç–¾ç—…åç§°ï¼ˆä¸è¦JSONæ ¼å¼ï¼‰ï¼š
"""
        else:
            prompt = f"""
As a GWAS database expert, please standardize the following disease name to common terminology used in GWAS databases:

Original disease name: {request.outcome_trait}

Important rules:
1. Return only the standard disease name, do not add gene information or other modifiers
2. Use common disease terminology found in GWAS databases
3. Keep it simple, avoid compound queries
4. Common standardization examples:
   - "heart disease" â†’ "coronary heart disease"
   - "CHD" â†’ "coronary heart disease"
   - "T2D" â†’ "type 2 diabetes"
   - "alzheimer" â†’ "alzheimer disease"

Please return only the standardized disease name (no JSON format):
"""

        return prompt

    def _parse_llm_query(self, response: str, original_query: str) -> str:
        """è§£æLLMæŸ¥è¯¢ä¼˜åŒ–å“åº”"""

        # æ–°çš„ç®€åŒ–è§£æï¼šç›´æ¥æå–ç–¾ç—…åç§°
        optimized = response.strip()

        # ç§»é™¤å¯èƒ½çš„å¼•å·å’Œå¤šä½™å­—ç¬¦
        optimized = optimized.strip('"\'`')

        # ç§»é™¤å¯èƒ½çš„å‰ç¼€æ–‡æœ¬
        if ':' in optimized:
            optimized = optimized.split(':')[-1].strip()

        # éªŒè¯ä¼˜åŒ–ç»“æœçš„åˆç†æ€§
        if self._is_valid_disease_name(optimized):
            return optimized

        # å¦‚æœä¼˜åŒ–ç»“æœä¸åˆç†ï¼Œè¿”å›åŸå§‹æŸ¥è¯¢
        return original_query

    def _is_valid_disease_name(self, disease_name: str) -> bool:
        """éªŒè¯ç–¾ç—…åç§°æ˜¯å¦åˆç†"""
        if not disease_name or len(disease_name) < 3:
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸åº”è¯¥å‡ºç°çš„å†…å®¹
        invalid_patterns = [
            'AND', '&', '+', 'gene', 'expression', 'PCSK9', 'APOE',  # åŸºå› ç›¸å…³
            'analysis', 'study', 'research',  # ç ”ç©¶ç›¸å…³
            'with', 'including', 'associated',  # å¤åˆæŸ¥è¯¢
        ]

        disease_lower = disease_name.lower()
        for pattern in invalid_patterns:
            if pattern.lower() in disease_lower:
                return False

        return True

    def _create_knowledge_integration_prompt(self, request: CausalAnalysisRequest, mr_result: Dict[str, Any], knowledge_result: Dict[str, Any], language: str) -> str:
        """åˆ›å»ºçŸ¥è¯†æ•´åˆçš„LLMæç¤º"""

        if language == "zh":
            prompt = f"""
ä½œä¸ºç”Ÿç‰©åŒ»å­¦çŸ¥è¯†ä¸“å®¶ï¼Œè¯·æ•´åˆä»¥ä¸‹åˆ†æç»“æœï¼š

åŸºå› ï¼š{request.exposure_gene}
ç–¾ç—…ï¼š{request.outcome_trait}
MRåˆ†æç»“æœï¼š{mr_result.get('summary', {}).get('conclusion', 'æ— ç»“è®º')}

å¯ç”¨çŸ¥è¯†ï¼š
- åŸºå› æ³¨é‡Šï¼š{knowledge_result.get('gene_annotation', {}).get('gene_info', {}).get('description', 'æ— ä¿¡æ¯')}
- è¯ç‰©ä¿¡æ¯ï¼š{len(knowledge_result.get('drug_analysis', {}).get('targeting_drugs', []))} ä¸ªç›¸å…³è¯ç‰©

è¯·æä¾›ï¼š
1. ç»¼åˆç”Ÿç‰©å­¦è§£é‡Š
2. ä¸´åºŠæ„ä¹‰è¯„ä¼°
3. ç ”ç©¶å±€é™æ€§
4. åç»­ç ”ç©¶å»ºè®®

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "biological_explanation": "ç”Ÿç‰©å­¦æœºåˆ¶è§£é‡Š",
    "clinical_significance": "ä¸´åºŠæ„ä¹‰",
    "limitations": "ç ”ç©¶å±€é™æ€§",
    "future_directions": "åç»­ç ”ç©¶æ–¹å‘"
}}
"""
        else:
            prompt = f"""
As a biomedical knowledge expert, please integrate the following analysis results:

Gene: {request.exposure_gene}
Disease: {request.outcome_trait}
MR analysis results: {mr_result.get('summary', {}).get('conclusion', 'No conclusion')}

Available knowledge:
- Gene annotation: {knowledge_result.get('gene_annotation', {}).get('gene_info', {}).get('description', 'No information')}
- Drug information: {len(knowledge_result.get('drug_analysis', {}).get('targeting_drugs', []))} related drugs

Please provide:
1. Comprehensive biological explanation
2. Clinical significance assessment
3. Study limitations
4. Future research suggestions

Please respond in JSON format:
{{
    "biological_explanation": "biological mechanism explanation",
    "clinical_significance": "clinical significance",
    "limitations": "study limitations",
    "future_directions": "future research directions"
}}
"""

        return prompt

    def _parse_llm_integration(self, response: str) -> Dict[str, Any]:
        """è§£æLLMçŸ¥è¯†æ•´åˆå“åº”"""
        import json
        import re

        try:
            # å°è¯•è§£æJSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                integration_data = json.loads(json_match.group())
                return integration_data
        except:
            pass

        # å¤‡ç”¨è§£æ
        return {
            "biological_explanation": "Knowledge integration completed",
            "clinical_significance": "Moderate",
            "limitations": "Standard MR limitations apply",
            "future_directions": "Further validation needed"
        }

    def _create_comprehensive_interpretation_prompt(self, result, language: str) -> str:
        """åˆ›å»ºç»¼åˆè§£é‡Šçš„LLMæç¤º"""

        # æå–MRç»“è®ºå’Œè¯¦ç»†ç»“æœ
        mr_conclusion = "æ— MRç»“æœ"
        mr_details = ""
        if result.mr_results and isinstance(result.mr_results, dict):
            mr_conclusion = result.mr_results.get('summary', {}).get('conclusion', 'æ— ç»“è®º')

            # æå–MRæ–¹æ³•ç»“æœ
            mr_results_list = result.mr_results.get('results', [])
            if mr_results_list:
                mr_details = "\nMRæ–¹æ³•ç»“æœï¼š\n"
                for method_result in mr_results_list[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæ–¹æ³•
                    method_name = method_result.get('method', 'Unknown')
                    estimate = method_result.get('estimate', 0)
                    p_value = method_result.get('p_value', 1)
                    mr_details += f"- {method_name}: Î²={estimate:.4f}, P={p_value:.3e}\n"

        # æå–åŸºå› æ³¨é‡Šä¿¡æ¯
        gene_info = ""
        if result.gene_annotation:
            gene_data = result.gene_annotation.get('gene_info', {})
            if gene_data:
                protein_name = gene_data.get('protein_name', '')
                function = gene_data.get('function', '')
                if protein_name:
                    gene_info += f"\nè›‹ç™½è´¨ï¼š{protein_name}"
                if function:
                    gene_info += f"\nåŠŸèƒ½ï¼š{function[:200]}..."

        # æå–è¯ç‰©ä¿¡æ¯
        drug_info = ""
        if result.drug_analysis:
            drug_targets = result.drug_analysis.get('targeting_drugs', [])
            if drug_targets:
                drug_info = f"\nç›¸å…³è¯ç‰©ï¼šå‘ç°{len(drug_targets)}ä¸ªç›¸å…³è¯ç‰©é¶ç‚¹"

        if language == "zh":
            prompt = f"""
ä½œä¸ºä¸“ä¸šçš„é—ä¼ æµè¡Œç—…å­¦å’Œå› æœæ¨æ–­ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹å­Ÿå¾·å°”éšæœºåŒ–åˆ†ææä¾›å…¨é¢æ·±å…¥çš„è§£é‡Šï¼š

## åˆ†ææ¦‚è§ˆ
- æš´éœ²åŸºå› ï¼š{result.request.exposure_gene}
- ç»“å±€ç–¾ç—…ï¼š{result.request.outcome_trait}
- ç»„ç»‡èƒŒæ™¯ï¼š{result.request.tissue_context}
- eQTLå·¥å…·å˜é‡ï¼š{result.summary.get('n_instruments', 0)}ä¸ª
- åè°ƒSNPï¼š{result.summary.get('n_harmonized_snps', 0)}ä¸ª

## MRåˆ†æç»“æœ
{mr_conclusion}{mr_details}

## ç”Ÿç‰©å­¦èƒŒæ™¯{gene_info}{drug_info}

è¯·æä¾›è¯¦ç»†çš„ä¸“ä¸šè§£é‡Šï¼ŒåŒ…æ‹¬ï¼š
1. **ä¸»è¦å‘ç°æ€»ç»“** - æ¸…æ™°æ¦‚è¿°å› æœå…³ç³»è¯æ®
2. **ç”Ÿç‰©å­¦æœºåˆ¶è§£é‡Š** - åŸºäºåŸºå› åŠŸèƒ½å’Œç–¾ç—…ç—…ç†çš„æœºåˆ¶åˆ†æ
3. **ç»Ÿè®¡å­¦è¯æ®è¯„ä¼°** - MRæ–¹æ³•ç»“æœçš„å¯é æ€§åˆ†æ
4. **ä¸´åºŠè½¬åŒ–æ„ä¹‰** - å¯¹ç–¾ç—…é¢„é˜²å’Œæ²»ç–—çš„å¯ç¤º
5. **ç ”ç©¶å±€é™æ€§** - å½“å‰åˆ†æçš„é™åˆ¶å’Œæ³¨æ„äº‹é¡¹
6. **åç»­ç ”ç©¶å»ºè®®** - å…·ä½“çš„éªŒè¯å’Œæ‰©å±•ç ”ç©¶æ–¹å‘

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "interpretation": "è¯¦ç»†çš„ä¸“ä¸šè§£é‡Šï¼ˆåŒ…å«ä»¥ä¸Š6ä¸ªæ–¹é¢ï¼Œä½¿ç”¨markdownæ ¼å¼ï¼‰",
    "recommendations": ["å…·ä½“å»ºè®®1", "å…·ä½“å»ºè®®2", "å…·ä½“å»ºè®®3", "å…·ä½“å»ºè®®4", "å…·ä½“å»ºè®®5"],
    "summary": {{
        "causal_conclusion": "å› æœç»“è®º",
        "confidence_level": "é«˜/ä¸­/ä½",
        "clinical_relevance": "ä¸´åºŠç›¸å…³æ€§è¯„ä¼°"
    }}
}}
"""
        else:
            prompt = f"""
As a professional genetic epidemiologist and causal inference expert, please provide a comprehensive and detailed interpretation for the following Mendelian Randomization analysis:

## Analysis Overview
- Exposure Gene: {result.request.exposure_gene}
- Outcome Disease: {result.request.outcome_trait}
- Tissue Context: {result.request.tissue_context}
- eQTL Instruments: {result.summary.get('n_instruments', 0)}
- Harmonized SNPs: {result.summary.get('n_harmonized_snps', 0)}

## MR Analysis Results
{mr_conclusion}{mr_details}

## Biological Context{gene_info}{drug_info}

Please provide a detailed professional interpretation covering:
1. **Main Findings Summary** - Clear overview of causal evidence
2. **Biological Mechanism Explanation** - Mechanism analysis based on gene function and disease pathology
3. **Statistical Evidence Assessment** - Reliability analysis of MR method results
4. **Clinical Translation Significance** - Implications for disease prevention and treatment
5. **Study Limitations** - Current analysis limitations and considerations
6. **Future Research Directions** - Specific validation and extension research directions

Please respond in JSON format:
{{
    "interpretation": "detailed professional interpretation (covering all 6 aspects above, using markdown format)",
    "recommendations": ["specific recommendation1", "specific recommendation2", "specific recommendation3", "specific recommendation4", "specific recommendation5"],
    "summary": {{
        "causal_conclusion": "causal conclusion",
        "confidence_level": "high/medium/low",
        "clinical_relevance": "clinical relevance assessment"
    }}
}}
"""

        return prompt

    def _parse_llm_interpretation(self, response: str) -> Dict[str, Any]:
        """è§£æLLMç»¼åˆè§£é‡Šå“åº”"""
        import json
        import re

        try:
            # å°è¯•è§£æJSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                interpretation_data = json.loads(json_match.group())
                # éªŒè¯å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
                if interpretation_data.get("interpretation") and interpretation_data.get("recommendations"):
                    return interpretation_data
        except Exception as e:
            logger.warning(f"JSONè§£æå¤±è´¥: {e}")

        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»åŸå§‹å“åº”ä¸­æå–å†…å®¹
        logger.info("å°è¯•ä»åŸå§‹LLMå“åº”ä¸­æå–å†…å®¹")

        # æå–è§£é‡Šå†…å®¹ï¼ˆæŸ¥æ‰¾å¸¸è§çš„æ ‡é¢˜æ¨¡å¼ï¼‰
        interpretation_content = response
        if "interpretation" in response.lower() or "è§£é‡Š" in response:
            # å°è¯•æå–è§£é‡Šéƒ¨åˆ†
            lines = response.split('\n')
            interpretation_lines = []
            in_interpretation = False

            for line in lines:
                if any(keyword in line.lower() for keyword in ["interpretation", "è§£é‡Š", "åˆ†æç»“æœ", "ä¸»è¦å‘ç°"]):
                    in_interpretation = True
                    continue
                elif any(keyword in line.lower() for keyword in ["recommendation", "å»ºè®®", "suggestions"]):
                    break
                elif in_interpretation and line.strip():
                    interpretation_lines.append(line.strip())

            if interpretation_lines:
                interpretation_content = '\n'.join(interpretation_lines)

        # å¤‡ç”¨è§£æ - ä½¿ç”¨åŸå§‹å“åº”å†…å®¹
        return {
            "interpretation": interpretation_content if interpretation_content.strip() else "LLMç”Ÿæˆäº†å“åº”ï¼Œä½†æ ¼å¼è§£æå¤±è´¥ã€‚è¯·æŸ¥çœ‹è¯¦ç»†çš„MRåˆ†æç»“æœã€‚",
            "recommendations": [
                "æŸ¥çœ‹MRåˆ†æç»“æœä¸­çš„å› æœè¯æ®",
                "è€ƒè™‘ç”Ÿç‰©å­¦èƒŒæ™¯å’Œæœºåˆ¶",
                "é€šè¿‡é¢å¤–ç ”ç©¶éªŒè¯å‘ç°",
                "è¯„ä¼°ç ”ç©¶çš„å±€é™æ€§",
                "è€ƒè™‘ä¸´åºŠè½¬åŒ–çš„å¯èƒ½æ€§"
            ],
            "summary": {
                "causal_conclusion": "åˆ†æå·²å®Œæˆ",
                "confidence_level": "ä¸­ç­‰",
                "clinical_relevance": "ä¸­ç­‰"
            }
        }

    def _parse_llm_methods(self, response: str) -> List[str]:
        """è§£æLLMæ–¹æ³•é€‰æ‹©å“åº”"""
        methods = []

        # æŸ¥æ‰¾å¸¸è§MRæ–¹æ³•
        common_methods = ["IVW", "Weighted Median", "MR-Egger", "Weighted Mode", "Simple Mode"]

        for method in common_methods:
            if method.lower() in response.lower():
                methods.append(method)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•
        if not methods:
            methods = ["IVW", "Weighted Median"]

        return methods

    def _parse_llm_integration(self, response: str) -> Dict[str, Any]:
        """è§£æLLMçŸ¥è¯†æ•´åˆå“åº”"""
        return {
            "integrated_summary": response[:500],  # å–å‰500å­—ç¬¦
            "key_insights": [response[:200]],  # ç®€åŒ–å¤„ç†
            "biological_context": response[200:400] if len(response) > 200 else ""
        }

    def _parse_llm_interpretation(self, response: str) -> Dict[str, Any]:
        """è§£æLLMç»¼åˆè§£é‡Šå“åº”"""
        import json
        import re

        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                interpretation = json.loads(json_match.group())
                return interpretation
        except:
            pass

        # å¤‡ç”¨è§£æï¼šå°†å“åº”åˆ†æ®µ
        lines = [line.strip() for line in response.split('\n') if line.strip()]

        interpretation = lines[0] if lines else "åˆ†æå®Œæˆ"
        recommendations = lines[1:3] if len(lines) > 1 else ["æŸ¥çœ‹è¯¦ç»†ç»“æœ"]

        return {
            "interpretation": interpretation,
            "recommendations": recommendations,
            "summary": {"status": "completed", "llm_generated": True}
        }
    
    async def continue_analysis_with_clarification(self, clarified_input: str, language: str = "zh") -> CausalAnalysisResult:
        """
        åŸºäºç”¨æˆ·æ¾„æ¸…ç»§ç»­åˆ†æ
        
        Args:
            clarified_input: ç”¨æˆ·æ¾„æ¸…åçš„è¾“å…¥
            language: è¯­è¨€ä»£ç 
            
        Returns:
            CausalAnalysisResult: åˆ†æç»“æœ
        """
        # é‡æ–°è§£ææ¾„æ¸…åçš„è¾“å…¥
        return await self.execute_analysis(clarified_input, language)
